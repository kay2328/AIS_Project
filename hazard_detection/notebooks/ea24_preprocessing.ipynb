{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Configure Logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Libraries imported and logging configured successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Directories and Paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "\n",
    "We define the base directory for raw datasets and a new combined_dataset directory to store preprocessed data, separating images and labels as per YOLOv5 conventions. The Path object ensures cross-platform compatibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory containing raw datasets\n",
    "base_dir = Path('../datasets')\n",
    "logger.debug(f\"Base directory set to: {base_dir}\")\n",
    "\n",
    "# Combined dataset directory\n",
    "combined_dataset_dir = base_dir / 'combined_dataset'\n",
    "combined_images_dir = combined_dataset_dir / 'images'\n",
    "combined_labels_dir = combined_dataset_dir / 'labels'\n",
    "\n",
    "# Create directories if they don’t exist\n",
    "for dir_path in [combined_images_dir, combined_labels_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    logger.debug(f\"Ensured directory exists: {dir_path}\")\n",
    "\n",
    "logger.info(\"Directory structure initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Classes and Mappings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "We define 10 classes, removing 'pedestrian' and combining 'bicycle' and 'motorcycle' into 'bike'. The class_to_id dictionary assigns YOLOv5-compatible integer IDs. The class_mapping handles synonyms and excludes unwanted classes (e.g., 'People', 'person'). The get_final_class function ensures only selected classes are retained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final selected classes (10 classes after adjustments)\n",
    "selected_classes = ['door', 'table', 'openedDoor', 'chair', 'pole', 'bike', 'truck', 'car', 'dog', 'bus']\n",
    "class_to_id = {cls: idx for idx, cls in enumerate(selected_classes)}\n",
    "logger.debug(f\"Selected classes: {selected_classes}\")\n",
    "logger.debug(f\"Class to ID mapping: {class_to_id}\")\n",
    "\n",
    "# Class mapping to standardize and filter classes\n",
    "class_mapping = {\n",
    "    'motorbike': 'bike',\n",
    "    'bicycle': 'bike',\n",
    "    'motorcycle': 'bike',\n",
    "    'open_door': 'openedDoor',\n",
    "    'People': None,  # Ignored (maps to pedestrian)\n",
    "    'person': None   # Ignored (maps to pedestrian)\n",
    "}\n",
    "logger.debug(f\"Class mapping defined: {class_mapping}\")\n",
    "\n",
    "def get_final_class(cls):\n",
    "    \"\"\"Map a class name to its final form or None if ignored.\"\"\"\n",
    "    mapped_cls = class_mapping.get(cls, cls)\n",
    "    final_cls = mapped_cls if mapped_cls in selected_classes else None\n",
    "    logger.debug(f\"Mapping class '{cls}' -> '{mapped_cls}' -> Final: '{final_cls}'\")\n",
    "    return final_cls\n",
    "\n",
    "logger.info(\"Class definitions and mapping function initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "find_image_file handles variable image extensions, while convert_to_yolo_format normalizes bounding boxes to the YOLO format (center_x, center_y, width, height) required by YOLOv5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_file(img_folder, base_name):\n",
    "    \"\"\"Find an image file with possible extensions.\"\"\"\n",
    "    for ext in ['.jpg', '.jpeg', '.png']:\n",
    "        candidate = img_folder / (base_name + ext)\n",
    "        if candidate.exists():\n",
    "            logger.debug(f\"Found image: {candidate}\")\n",
    "            return candidate\n",
    "    logger.warning(f\"No image found for base name {base_name} in {img_folder}\")\n",
    "    return None\n",
    "\n",
    "def convert_to_yolo_format(bbox, img_width, img_height):\n",
    "    \"\"\"Convert bounding box from [xmin, ymin, xmax, ymax] to YOLO format.\"\"\"\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    center_x = (xmin + xmax) / 2 / img_width\n",
    "    center_y = (ymin + ymax) / 2 / img_height\n",
    "    width = (xmax - xmin) / img_width\n",
    "    height = (ymax - ymin) / img_height\n",
    "    logger.debug(f\"Converted bbox {bbox} to YOLO: [{center_x}, {center_y}, {width}, {height}]\")\n",
    "    return center_x, center_y, width, height\n",
    "\n",
    "logger.info(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Ninja Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "This function processes the ninja dataset, which uses JSON annotations. It combines all splits (train, valid, test) into one dataset, prefixes filenames with 'n_', converts bounding boxes to YOLO format, and logs every step. Empty label files are created for images with no selected classes, aligning with YOLOv5 practices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ninja(ninja_folder, combined_images_folder, combined_labels_folder):\n",
    "    prefix = 'n_'\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    image_count = 0\n",
    "    label_count = 0\n",
    "\n",
    "    for split in splits:\n",
    "        ann_folder = ninja_folder / split / 'ann'\n",
    "        img_folder = ninja_folder / split / 'img'\n",
    "        if not ann_folder.exists() or not img_folder.exists():\n",
    "            logger.warning(f\"Missing 'ann' or 'img' folder in {split} split of ninja\")\n",
    "            continue\n",
    "\n",
    "        ann_files = list(ann_folder.glob('*.json'))\n",
    "        logger.info(f\"Found {len(ann_files)} annotation files in ninja {split}\")\n",
    "\n",
    "        for ann_file in tqdm(ann_files, desc=f\"Processing ninja {split}\"):\n",
    "            try:\n",
    "                base_name = ann_file.stem.split('.')[0]  # e.g., '109' from '109.png.json'\n",
    "                img_file = find_image_file(img_folder, base_name)\n",
    "                if not img_file:\n",
    "                    continue\n",
    "\n",
    "                # Copy image with prefix\n",
    "                new_img_name = f\"{prefix}{img_file.name}\"\n",
    "                new_img_path = combined_images_folder / new_img_name\n",
    "                shutil.copy(img_file, new_img_path)\n",
    "                image_count += 1\n",
    "                logger.debug(f\"Copied image to {new_img_path}\")\n",
    "\n",
    "                # Parse JSON\n",
    "                with open(ann_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                width = data['size']['width']\n",
    "                height = data['size']['height']\n",
    "                objects = data.get('objects', [])\n",
    "                lines = []\n",
    "\n",
    "                for obj in objects:\n",
    "                    cls = obj.get('classTitle', 'unknown')\n",
    "                    final_cls = get_final_class(cls)\n",
    "                    if final_cls is None:\n",
    "                        continue\n",
    "                    points = obj.get('points', {}).get('exterior', [])\n",
    "                    if len(points) != 2:\n",
    "                        logger.warning(f\"Invalid points data in {ann_file}: {points}\")\n",
    "                        continue\n",
    "                    xmin, ymin = points[0]\n",
    "                    xmax, ymax = points[1]\n",
    "                    bbox = [xmin, ymin, xmax, ymax]\n",
    "                    center_x, center_y, box_width, box_height = convert_to_yolo_format(bbox, width, height)\n",
    "                    class_id = class_to_id[final_cls]\n",
    "                    line = f\"{class_id} {center_x:.6f} {center_y:.6f} {box_width:.6f} {box_height:.6f}\"\n",
    "                    lines.append(line)\n",
    "\n",
    "                # Write label file (empty if no objects)\n",
    "                new_label_name = new_img_name.rsplit('.', 1)[0] + '.txt'\n",
    "                new_label_path = combined_labels_folder / new_label_name\n",
    "                with open(new_label_path, 'w') as f:\n",
    "                    f.write('\\n'.join(lines))\n",
    "                label_count += 1\n",
    "                logger.debug(f\"Wrote label file {new_label_path} with {len(lines)} annotations\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {ann_file}: {e}\")\n",
    "\n",
    "    logger.info(f\"Ninja processed: {image_count} images, {label_count} labels\")\n",
    "    return image_count, label_count\n",
    "\n",
    "ninja_counts = process_ninja(base_dir / 'ninja', combined_images_dir, combined_labels_dir)\n",
    "print(f\"Ninja results: Images: {ninja_counts[0]}, Labels: {ninja_counts[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process WOTR Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "For WOTR, we handle XML annotations, noting that the XML filename (not the internal tag) links to the image. We prefix filenames with 'w_' and convert bounding boxes to YOLO format, accounting for the nested 'WOTR' folder structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wotr(wotr_folder, combined_images_folder, combined_labels_folder):\n",
    "    prefix = 'w_'\n",
    "    ann_folder = wotr_folder / 'WOTR' / 'Annotations'\n",
    "    img_folder = wotr_folder / 'WOTR' / 'JPEGImages'\n",
    "    image_count = 0\n",
    "    label_count = 0\n",
    "\n",
    "    if not ann_folder.exists() or not img_folder.exists():\n",
    "        logger.error(f\"Cannot find 'Annotations' or 'JPEGImages' in {wotr_folder}\")\n",
    "        return 0, 0\n",
    "\n",
    "    ann_files = list(ann_folder.glob('*.xml'))\n",
    "    logger.info(f\"Found {len(ann_files)} XML annotation files in WOTR\")\n",
    "\n",
    "    for ann_file in tqdm(ann_files, desc=\"Processing WOTR\"):\n",
    "        try:\n",
    "            base_name = ann_file.stem  # Use XML filename, not internal tag\n",
    "            img_path = img_folder / f\"{base_name}.jpg\"\n",
    "            if not img_path.exists():\n",
    "                logger.warning(f\"No image found for {ann_file} at {img_path}\")\n",
    "                continue\n",
    "\n",
    "            new_img_name = f\"{prefix}{img_path.name}\"\n",
    "            new_img_path = combined_images_folder / new_img_name\n",
    "            shutil.copy(img_path, new_img_path)\n",
    "            image_count += 1\n",
    "            logger.debug(f\"Copied image to {new_img_path}\")\n",
    "\n",
    "            tree = ET.parse(ann_file)\n",
    "            root = tree.getroot()\n",
    "            size = root.find('size')\n",
    "            width = int(size.find('width').text)\n",
    "            height = int(size.find('height').text)\n",
    "            objects = root.findall('object')\n",
    "            lines = []\n",
    "\n",
    "            for obj in objects:\n",
    "                cls = obj.find('name').text\n",
    "                final_cls = get_final_class(cls)\n",
    "                if final_cls is None:\n",
    "                    continue\n",
    "                bndbox = obj.find('bndbox')\n",
    "                xmin = float(bndbox.find('xmin').text)\n",
    "                ymin = float(bndbox.find('ymin').text)\n",
    "                xmax = float(bndbox.find('xmax').text)\n",
    "                ymax = float(bndbox.find('ymax').text)\n",
    "                bbox = [xmin, ymin, xmax, ymax]\n",
    "                center_x, center_y, box_width, box_height = convert_to_yolo_format(bbox, width, height)\n",
    "                class_id = class_to_id[final_cls]\n",
    "                line = f\"{class_id} {center_x:.6f} {center_y:.6f} {box_width:.6f} {box_height:.6f}\"\n",
    "                lines.append(line)\n",
    "\n",
    "            new_label_name = new_img_name.rsplit('.', 1)[0] + '.txt'\n",
    "            new_label_path = combined_labels_folder / new_label_name\n",
    "            with open(new_label_path, 'w') as f:\n",
    "                f.write('\\n'.join(lines))\n",
    "            label_count += 1\n",
    "            logger.debug(f\"Wrote label file {new_label_path} with {len(lines)} annotations\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {ann_file}: {e}\")\n",
    "\n",
    "    logger.info(f\"WOTR processed: {image_count} images, {label_count} labels\")\n",
    "    return image_count, label_count\n",
    "\n",
    "wotr_counts = process_wotr(base_dir / 'WOTR', combined_images_dir, combined_labels_dir)\n",
    "print(f\"WOTR results: Images: {wotr_counts[0]}, Labels: {wotr_counts[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Risk-Detection Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "The risk-detection dataset is already in YOLO format, so we remap class IDs to our unified list, excluding 'pedestrian'. All splits are combined, and filenames are prefixed with 'r_'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_risk_detection(risk_folder, combined_images_folder, combined_labels_folder):\n",
    "    prefix = 'r_'\n",
    "    yaml_path = risk_folder / 'data.yaml'\n",
    "    image_count = 0\n",
    "    label_count = 0\n",
    "\n",
    "    if not yaml_path.exists():\n",
    "        logger.error(f\"data.yaml not found in {risk_folder}\")\n",
    "        return 0, 0\n",
    "\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data_yaml = yaml.safe_load(f)\n",
    "    class_names = data_yaml.get('names', [])\n",
    "    logger.debug(f\"Loaded class names from data.yaml: {class_names}\")\n",
    "\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    for split in splits:\n",
    "        label_folder = risk_folder / split / 'labels'\n",
    "        img_folder = risk_folder / split / 'images'\n",
    "        if not label_folder.exists() or not img_folder.exists():\n",
    "            logger.warning(f\"Missing 'labels' or 'images' in {split} split of risk-detection\")\n",
    "            continue\n",
    "\n",
    "        label_files = list(label_folder.glob('*.txt'))\n",
    "        logger.info(f\"Found {len(label_files)} label files in risk-detection {split}\")\n",
    "\n",
    "        for label_file in tqdm(label_files, desc=f\"Processing risk-detection {split}\"):\n",
    "            try:\n",
    "                base_name = label_file.stem\n",
    "                img_file = find_image_file(img_folder, base_name)\n",
    "                if not img_file:\n",
    "                    continue\n",
    "\n",
    "                new_img_name = f\"{prefix}{img_file.name}\"\n",
    "                new_img_path = combined_images_folder / new_img_name\n",
    "                shutil.copy(img_file, new_img_path)\n",
    "                image_count += 1\n",
    "                logger.debug(f\"Copied image to {new_img_path}\")\n",
    "\n",
    "                with open(label_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                new_lines = []\n",
    "\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if not parts:\n",
    "                        continue\n",
    "                    class_idx = int(parts[0])\n",
    "                    if class_idx >= len(class_names):\n",
    "                        logger.warning(f\"Class index {class_idx} out of range in {label_file}\")\n",
    "                        continue\n",
    "                    cls = class_names[class_idx]\n",
    "                    final_cls = get_final_class(cls)\n",
    "                    if final_cls is None:\n",
    "                        continue\n",
    "                    new_class_id = class_to_id[final_cls]\n",
    "                    new_line = f\"{new_class_id} {' '.join(parts[1:])}\"\n",
    "                    new_lines.append(new_line)\n",
    "\n",
    "                new_label_name = new_img_name.rsplit('.', 1)[0] + '.txt'\n",
    "                new_label_path = combined_labels_folder / new_label_name\n",
    "                with open(new_label_path, 'w') as f:\n",
    "                    f.write('\\n'.join(new_lines))\n",
    "                label_count += 1\n",
    "                logger.debug(f\"Wrote label file {new_label_path} with {len(new_lines)} annotations\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {label_file}: {e}\")\n",
    "\n",
    "    logger.info(f\"Risk-detection processed: {image_count} images, {label_count} labels\")\n",
    "    return image_count, label_count\n",
    "\n",
    "risk_counts = process_risk_detection(base_dir / 'risk-detection-1', combined_images_dir, combined_labels_dir)\n",
    "print(f\"Risk-detection results: Images: {risk_counts[0]}, Labels: {risk_counts[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Size Analysis and Decision on Resizing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "We analyze image sizes to consider resizing but opt against it. YOLOv5 resizes images on-the-fly during training, and since annotations are normalized, keeping original sizes preserves detail and simplifies preprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_sizes():\n",
    "    all_sizes = []\n",
    "    for img_file in combined_images_dir.glob('*'):\n",
    "        try:\n",
    "            img = cv2.imread(str(img_file))\n",
    "            if img is None:\n",
    "                logger.warning(f\"Failed to load image {img_file}\")\n",
    "                continue\n",
    "            height, width = img.shape[:2]\n",
    "            all_sizes.append((width, height))\n",
    "            logger.debug(f\"Image {img_file}: {width}x{height}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing {img_file}: {e}\")\n",
    "\n",
    "    if not all_sizes:\n",
    "        logger.warning(\"No image sizes to analyze\")\n",
    "        return\n",
    "\n",
    "    widths, heights = zip(*all_sizes)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(widths, bins=30, alpha=0.5, label='Width')\n",
    "    plt.hist(heights, bins=30, alpha=0.5, label='Height')\n",
    "    plt.title('Image Size Distribution')\n",
    "    plt.xlabel('Pixels')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    logger.info(f\"Image size stats - Width: min={min(widths)}, max={max(widths)}, avg={np.mean(widths):.2f}\")\n",
    "    logger.info(f\"Image size stats - Height: min={min(heights)}, max={max(heights)}, avg={np.mean(heights):.2f}\")\n",
    "\n",
    "analyze_image_sizes()\n",
    "logger.info(\"Decision: Not resizing images to preserve annotation accuracy; YOLOv5 will handle resizing during training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Dataset Integrity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "We check for unpaired images and labels, logging any discrepancies. A sample image with bounding boxes is visualized to confirm correct annotation conversion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_dataset():\n",
    "    image_files = set(f.stem for f in combined_images_dir.glob('*'))\n",
    "    label_files = set(f.stem for f in combined_labels_dir.glob('*.txt'))\n",
    "    \n",
    "    missing_labels = image_files - label_files\n",
    "    missing_images = label_files - image_files\n",
    "    \n",
    "    logger.info(f\"Total images: {len(image_files)}, Total labels: {len(label_files)}\")\n",
    "    if missing_labels:\n",
    "        logger.warning(f\"Images missing labels: {len(missing_labels)} - {list(missing_labels)[:5]}\")\n",
    "    if missing_images:\n",
    "        logger.warning(f\"Labels missing images: {len(missing_images)} - {list(missing_images)[:5]}\")\n",
    "    \n",
    "    # Visualize a sample\n",
    "    sample_img = next(iter(combined_images_dir.glob('*')))\n",
    "    sample_label = combined_labels_dir / (sample_img.stem + '.txt')\n",
    "    img = cv2.imread(str(sample_img))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    if sample_label.exists():\n",
    "        with open(sample_label, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            class_id, cx, cy, w, h = map(float, line.split())\n",
    "            xmin = int((cx - w / 2) * width)\n",
    "            ymin = int((cy - h / 2) * height)\n",
    "            xmax = int((cx + w / 2) * width)\n",
    "            ymax = int((cy + h / 2) * height)\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(img, selected_classes[int(class_id)], (xmin, ymin - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Sample: {sample_img.name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "verify_dataset()\n",
    "logger.info(\"Dataset verification completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Find label files with and without annotations\n",
    "label_files_with_annotations = [f for f in combined_labels_dir.glob('*.txt') if f.stat().st_size > 0]\n",
    "label_files_without_annotations = [f for f in combined_labels_dir.glob('*.txt') if f.stat().st_size == 0]\n",
    "\n",
    "# Randomly select one from each\n",
    "label_with_annotations = random.choice(label_files_with_annotations) if label_files_with_annotations else None\n",
    "label_without_annotations = random.choice(label_files_without_annotations) if label_files_without_annotations else None\n",
    "\n",
    "img_with_annotations = combined_images_dir / (label_with_annotations.stem + '.jpg') if label_with_annotations else None\n",
    "img_without_annotations = combined_images_dir / (label_without_annotations.stem + '.jpg') if label_without_annotations else None\n",
    "\n",
    "# Function to plot image with or without bounding boxes\n",
    "def plot_image(img_path, label_path, title):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    if label_path.exists() and label_path.stat().st_size > 0:\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if parts:  # Ensure line is not empty\n",
    "                class_id, cx, cy, w, h = map(float, parts)\n",
    "                xmin = int((cx - w / 2) * width)\n",
    "                ymin = int((cy - h / 2) * height)\n",
    "                xmax = int((cx + w / 2) * width)\n",
    "                ymax = int((cy + h / 2) * height)\n",
    "                cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                class_name = selected_classes[int(class_id)]\n",
    "                cv2.putText(img, class_name, (xmin, ymin - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot both images with descriptive titles\n",
    "if img_with_annotations:\n",
    "    plot_image(img_with_annotations, label_with_annotations, \n",
    "               f\"Image with Annotations from Selected Classes: {img_with_annotations.name}\")\n",
    "else:\n",
    "    print(\"No images with annotations found.\")\n",
    "\n",
    "if img_without_annotations:\n",
    "    plot_image(img_without_annotations, label_without_annotations, \n",
    "               f\"Image with Empty Label File: {img_without_annotations.name}\")\n",
    "else:\n",
    "    print(\"No images without annotations found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Images with Bounding Boxes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_with_class(class_name, num_images=1):\n",
    "    \"\"\"Get a list of images that contain the specified class.\"\"\"\n",
    "    images_with_class = []\n",
    "    for label_file in combined_labels_dir.glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            class_id = int(line.split()[0])\n",
    "            if class_id < len(selected_classes) and selected_classes[class_id] == class_name:\n",
    "                img_name = label_file.stem + '.jpg'  \n",
    "                images_with_class.append(img_name)\n",
    "                break\n",
    "        if len(images_with_class) >= num_images:\n",
    "            break\n",
    "    print(f\"Found {len(images_with_class)} images for class '{class_name}'\")\n",
    "    return images_with_class\n",
    "\n",
    "def get_random_images(num_images=4):\n",
    "    \"\"\"Get a list of random images from the dataset.\"\"\"\n",
    "    all_images = list(combined_images_dir.glob('*.jpg'))  \n",
    "    return [img.name for img in random.sample(all_images, min(num_images, len(all_images)))]\n",
    "\n",
    "def plot_images_with_boxes(image_list, n_cols=4):\n",
    "    \"\"\"Plot images with bounding boxes in a grid.\"\"\"\n",
    "    n_images = len(image_list)\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, img_name in enumerate(image_list):\n",
    "        img_path = combined_images_dir / img_name\n",
    "        label_path = combined_labels_dir / (img_path.stem + '.txt')\n",
    "\n",
    "        # Load image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        height, width = img.shape[:2]\n",
    "\n",
    "        # Load and draw labels\n",
    "        boxes_drawn = 0\n",
    "        if label_path.exists() and label_path.stat().st_size > 0:\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5:\n",
    "                    print(f\"Invalid label format in {label_path}: {line.strip()}\")\n",
    "                    continue\n",
    "                class_id = int(parts[0])\n",
    "                if class_id >= len(selected_classes):\n",
    "                    print(f\"Class ID {class_id} out of range in {label_path}\")\n",
    "                    continue\n",
    "                cx, cy, w, h = map(float, parts[1:])\n",
    "                xmin = int((cx - w / 2) * width)\n",
    "                ymin = int((cy - h / 2) * height)\n",
    "                xmax = int((cx + w / 2) * width)\n",
    "                ymax = int((cy + h / 2) * height)\n",
    "                cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                cv2.putText(img, selected_classes[class_id], (xmin, ymin - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                boxes_drawn += 1\n",
    "            print(f\"Drew {boxes_drawn} boxes for {img_name}\")\n",
    "        else:\n",
    "            print(f\"No labels or empty label file for {img_name}\")\n",
    "\n",
    "        # Plot image\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(img_name)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Hide unused axes\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Collect images\n",
    "images_to_plot = []\n",
    "for cls in selected_classes:\n",
    "    images_to_plot.extend(get_images_with_class(cls, num_images=1))\n",
    "images_to_plot.extend(get_random_images(num_images=4))\n",
    "images_to_plot = list(set(images_to_plot))  # Remove duplicates\n",
    "\n",
    "print(f\"Total images to plot: {len(images_to_plot)}\")\n",
    "plot_images_with_boxes(images_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Visual Checks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# 1. Class Frequency Histogram\n",
    "class_counts = Counter()\n",
    "for label_file in combined_labels_dir.glob('*.txt'):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if parts:  # Skip empty lines\n",
    "            class_id = int(parts[0])\n",
    "            if class_id < len(selected_classes):\n",
    "                class_counts[selected_classes[class_id]] += 1\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.title('Class Frequency in Dataset')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Plot Images with No Annotations\n",
    "no_annotation_images = []\n",
    "for img_path in combined_images_dir.glob('*.jpg'):  \n",
    "    label_path = combined_labels_dir / (img_path.stem + '.txt')\n",
    "    if not label_path.exists() or label_path.stat().st_size == 0:\n",
    "        no_annotation_images.append(img_path.name)\n",
    "        if len(no_annotation_images) >= 4:  # Limit to 4 for display\n",
    "            break\n",
    "\n",
    "if no_annotation_images:\n",
    "    print(f\"Found {len(no_annotation_images)} images with no annotations. Plotting a sample:\")\n",
    "    n_cols = 4\n",
    "    n_rows = 1\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5))\n",
    "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "\n",
    "    for i, img_name in enumerate(no_annotation_images):\n",
    "        img = cv2.imread(str(combined_images_dir / img_name))\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(img_name)\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    for j in range(i + 1, n_cols):\n",
    "        axes[j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images with missing or empty annotations found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Frequency Histogram with Values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = Counter()\n",
    "for label_file in combined_labels_dir.glob('*.txt'):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if parts:\n",
    "            class_id = int(parts[0])\n",
    "            if class_id < len(selected_classes):\n",
    "                class_counts[selected_classes[class_id]] += 1\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.title('Class Frequency in Dataset')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.05, int(yval), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_for_class(class_name, num_images=4):\n",
    "    images_with_class = []\n",
    "    for label_file in combined_labels_dir.glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if parts and selected_classes[int(parts[0])] == class_name:\n",
    "                img_path = combined_images_dir / (label_file.stem + '.jpg')\n",
    "                if img_path.exists():\n",
    "                    images_with_class.append(img_path)\n",
    "                    if len(images_with_class) >= num_images:\n",
    "                        break\n",
    "        if len(images_with_class) >= num_images:\n",
    "            break\n",
    "    \n",
    "    if images_with_class:\n",
    "        fig, axes = plt.subplots(1, len(images_with_class), figsize=(15, 5))\n",
    "        for i, img_path in enumerate(images_with_class):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            label_path = combined_labels_dir / (img_path.stem + '.txt')\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            h, w = img.shape[:2]\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    class_id, x_center, y_center, width, height = map(float, parts)\n",
    "                    x_min = int((x_center - width/2) * w)\n",
    "                    y_min = int((y_center - height/2) * h)\n",
    "                    x_max = int((x_center + width/2) * w)\n",
    "                    y_max = int((y_center + height/2) * h)\n",
    "                    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "                    cv2.putText(img, selected_classes[int(class_id)], (x_min, y_min-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No images found for class '{class_name}'\")\n",
    "\n",
    "plot_images_for_class('car', num_images=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_stats():\n",
    "    total_images = len(list(combined_images_dir.glob('*.jpg')))\n",
    "    images_with_annotations = 0\n",
    "    images_without_annotations = 0\n",
    "    boxes_per_image = []\n",
    "\n",
    "    for label_file in combined_labels_dir.glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        num_boxes = len(lines)\n",
    "        boxes_per_image.append(num_boxes)\n",
    "        if num_boxes > 0:\n",
    "            images_with_annotations += 1\n",
    "        else:\n",
    "            images_without_annotations += 1\n",
    "\n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"Images with annotations: {images_with_annotations}\")\n",
    "    print(f\"Images without annotations: {images_without_annotations}\")\n",
    "    print(f\"Average boxes per image: {sum(boxes_per_image) / len(boxes_per_image) if boxes_per_image else 0:.2f}\")\n",
    "\n",
    "get_annotation_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_random_sample(num_samples=5):\n",
    "    all_images = list(combined_images_dir.glob('*.jpg'))\n",
    "    sample_images = random.sample(all_images, min(num_samples, len(all_images)))\n",
    "    for img_path in sample_images:\n",
    "        img_name = img_path.name\n",
    "        label_path = combined_labels_dir / (img_path.stem + '.txt')\n",
    "        if label_path.exists() and label_path.stat().st_size > 0:\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            print(f\"Image: {img_name}, Number of boxes: {len(lines)}\")\n",
    "        else:\n",
    "            print(f\"Image: {img_name}, No annotations\")\n",
    "\n",
    "verify_random_sample(num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label_files(num_files=3):\n",
    "    label_files = list(combined_labels_dir.glob('*.txt'))\n",
    "    sample_files = random.sample(label_files, min(num_files, len(label_files)))\n",
    "    for label_file in sample_files:\n",
    "        with open(label_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        print(f\"Label file: {label_file.name}\\nContent:\\n{content}\\n\")\n",
    "\n",
    "check_label_files(num_files=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw bounding boxes on an image\n",
    "def draw_boxes(img, label_path, selected_classes):\n",
    "    height, width = img.shape[:2]\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        class_id, cx, cy, w, h = map(float, parts[:5])\n",
    "        class_id = int(class_id)\n",
    "        if class_id < len(selected_classes):\n",
    "            class_name = selected_classes[class_id]\n",
    "            xmin = int((cx - w/2) * width)\n",
    "            ymin = int((cy - h/2) * height)\n",
    "            xmax = int((cx + w/2) * width)\n",
    "            ymax = int((cy + h/2) * height)\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            cv2.putText(img, class_name, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    return img\n",
    "\n",
    "# Collect images by class\n",
    "class_images = {cls: [] for cls in selected_classes}\n",
    "for label_file in combined_labels_dir.glob('*.txt'):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    classes_in_file = set()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if parts:\n",
    "            class_id = int(parts[0])\n",
    "            if class_id < len(selected_classes):\n",
    "                classes_in_file.add(selected_classes[class_id])\n",
    "    img_name = label_file.stem + '.jpg'\n",
    "    for cls in classes_in_file:\n",
    "        class_images[cls].append(img_name)\n",
    "\n",
    "# Plot random 5 images for each class\n",
    "for cls in selected_classes:\n",
    "    print(f\"\\nPlotting up to 5 images for class: {cls}\")\n",
    "    if not class_images[cls]:\n",
    "        print(f\"No images found for class: {cls}\")\n",
    "        continue\n",
    "    sample_images = random.sample(class_images[cls], min(5, len(class_images[cls])))\n",
    "    for img_name in sample_images:\n",
    "        img_path = combined_images_dir / img_name\n",
    "        label_path = combined_labels_dir / (img_path.stem + '.txt')\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {img_path}\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for Matplotlib\n",
    "        annotated_img = draw_boxes(img, label_path, selected_classes)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(annotated_img)\n",
    "        plt.title(f\"Class: {cls} - {img_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths and Create New Directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to combined images and labels\n",
    "combined_images_dir = Path('../datasets/combined_dataset/images')\n",
    "combined_labels_dir = Path('../datasets/combined_dataset/labels')\n",
    "preprocessed_images_dir = Path('../preprocessed_dataset/images')\n",
    "preprocessed_labels_dir = Path('../preprocessed_dataset/labels')\n",
    "\n",
    "# Create preprocessed directories if they don’t exist\n",
    "preprocessed_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "preprocessed_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Original images directory: {combined_images_dir}\")\n",
    "logger.info(f\"Original labels directory: {combined_labels_dir}\")\n",
    "logger.info(f\"Preprocessed images will be saved to: {preprocessed_images_dir}\")\n",
    "logger.info(f\"Preprocessed labels will be saved to: {preprocessed_labels_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible image extensions to check\n",
    "IMAGE_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "\n",
    "# Function to find an image file with any supported extension\n",
    "def find_image_file(stem, image_dir, extensions):\n",
    "    for ext in extensions:\n",
    "        candidate = image_dir / (stem + ext)\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s examine the dataset to understand its composition, as we know there are 70,901 images total, with 12,201 having annotations and 58,854 without.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all label files\n",
    "label_files = list(combined_labels_dir.glob('*.txt'))\n",
    "logger.info(f\"Total label files found: {len(label_files)}\")\n",
    "\n",
    "# Separate files with and without annotations\n",
    "label_files_with_annotations = [f for f in label_files if f.stat().st_size > 0]\n",
    "label_files_without_annotations = [f for f in label_files if f.stat().st_size == 0]\n",
    "\n",
    "logger.info(f\"Images with annotations: {len(label_files_with_annotations)}\")\n",
    "logger.info(f\"Images without annotations: {len(label_files_without_annotations)}\")\n",
    "\n",
    "# Verify corresponding images exist\n",
    "images_with_labels = [find_image_file(f.stem, combined_images_dir, IMAGE_EXTENSIONS) for f in label_files_with_annotations]\n",
    "images_without_labels = [find_image_file(f.stem, combined_images_dir, IMAGE_EXTENSIONS) for f in label_files_without_annotations]\n",
    "\n",
    "# Filter out None values where no image was found\n",
    "images_with_labels = [img for img in images_with_labels if img is not None]\n",
    "images_without_labels = [img for img in images_without_labels if img is not None]\n",
    "\n",
    "missing_images = [f for f in images_with_labels + images_without_labels if not f.exists()]\n",
    "if missing_images:\n",
    "    logger.warning(f\"Missing images: {len(missing_images)}. Examples: {missing_images[:5]}\")\n",
    "else:\n",
    "    logger.info(\"All label files have corresponding images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are far more images without labels, we’ll balance the dataset by selecting all 12,201 images with annotations and an equal number without annotations, totaling 24,402 images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all images with annotations\n",
    "selected_label_files = label_files_with_annotations.copy()\n",
    "N = len(label_files_with_annotations)\n",
    "\n",
    "# Randomly select an equal number of images without annotations\n",
    "if label_files_without_annotations:\n",
    "    selected_without_annotations = random.sample(label_files_without_annotations, min(N, len(label_files_without_annotations)))\n",
    "    selected_label_files.extend(selected_without_annotations)\n",
    "\n",
    "logger.info(f\"Selected {len(selected_label_files)} images for preprocessing:\")\n",
    "logger.info(f\"- With annotations: {len(label_files_with_annotations)}\")\n",
    "logger.info(f\"- Without annotations: {len(selected_label_files) - len(label_files_with_annotations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Preprocessing Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need functions to preprocess images (clean, resize, normalize) and adjust labels accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target size for YOLO\n",
    "S = 416\n",
    "\n",
    "def preprocess_image(img, S):\n",
    "    \"\"\"Resize image to SxS while maintaining aspect ratio, pad, and normalize.\"\"\"\n",
    "    if img is None:\n",
    "        return None, None\n",
    "    H, W = img.shape[:2]\n",
    "    scale = min(S / W, S / H)\n",
    "    new_W = int(W * scale)\n",
    "    new_H = int(H * scale)\n",
    "    resized_img = cv2.resize(img, (new_W, new_H), interpolation=cv2.INTER_LINEAR)\n",
    "    pad_left = (S - new_W) // 2\n",
    "    pad_top = (S - new_H) // 2\n",
    "    pad_right = S - new_W - pad_left\n",
    "    pad_bottom = S - new_H - pad_top\n",
    "    padded_img = cv2.copyMakeBorder(resized_img, pad_top, pad_bottom, pad_left, pad_right, \n",
    "                                    cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    normalized_img = padded_img.astype(np.float32) / 255.0\n",
    "    return normalized_img, (scale, pad_left, pad_top, S, W, H)\n",
    "\n",
    "def adjust_label(label_path, scale, pad_left, pad_top, S, W, H):\n",
    "    \"\"\"Adjust bounding box coordinates for resized and padded image.\"\"\"\n",
    "    if label_path.stat().st_size == 0:\n",
    "        return []\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if not parts:\n",
    "            continue\n",
    "        class_id = parts[0]\n",
    "        x_center_norm, y_center_norm, width_norm, height_norm = map(float, parts[1:])\n",
    "        # Convert to pixel coordinates\n",
    "        x_center = x_center_norm * W\n",
    "        y_center = y_center_norm * H\n",
    "        width = width_norm * W\n",
    "        height = height_norm * H\n",
    "        # Scale\n",
    "        x_center_scaled = x_center * scale\n",
    "        y_center_scaled = y_center * scale\n",
    "        width_scaled = width * scale\n",
    "        height_scaled = height * scale\n",
    "        # Add padding\n",
    "        x_center_padded = x_center_scaled + pad_left\n",
    "        y_center_padded = y_center_scaled + pad_top\n",
    "        # Normalize to [0,1]\n",
    "        x_center_new = x_center_padded / S\n",
    "        y_center_new = y_center_padded / S\n",
    "        width_new = width_scaled / S\n",
    "        height_new = height_scaled / S\n",
    "        new_lines.append(f\"{class_id} {x_center_new:.6f} {y_center_new:.6f} {width_new:.6f} {height_new:.6f}\")\n",
    "    return new_lines\n",
    "\n",
    "logger.info(f\"Preprocessing functions defined. Target size: {S}x{S}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Visualization Samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll visualize a few samples to verify preprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples = True\n",
    "num_samples = 2\n",
    "sampled_with_annotations = random.sample([f for f in selected_label_files if f.stat().st_size > 0], num_samples)\n",
    "sampled_without_annotations = random.sample([f for f in selected_label_files if f.stat().st_size == 0], num_samples)\n",
    "sampled_images = sampled_with_annotations + sampled_without_annotations\n",
    "\n",
    "logger.info(f\"Selected {len(sampled_images)} images for visualization:\")\n",
    "for sample in sampled_images:\n",
    "    logger.info(f\"- {sample.name} (Has annotations: {sample.stat().st_size > 0})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we process each selected image and label, with visualization for samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_file in tqdm(selected_label_files, desc=\"Preprocessing images\"):\n",
    "    image_file = find_image_file(label_file.stem, combined_images_dir, IMAGE_EXTENSIONS)\n",
    "    if image_file is None:\n",
    "        logger.warning(f\"Image file not found for label: {label_file}\")\n",
    "        continue\n",
    "    img = cv2.imread(str(image_file))\n",
    "    if img is None:\n",
    "        logger.warning(f\"Failed to read image: {image_file}\")\n",
    "        continue\n",
    "    \n",
    "    preprocessed_img, (scale, pad_left, pad_top, S, W, H) = preprocess_image(img, S)\n",
    "    \n",
    "    # Save preprocessed image as .jpg\n",
    "    preprocessed_image_path = preprocessed_images_dir / f\"{label_file.stem}.jpg\"\n",
    "    cv2.imwrite(str(preprocessed_image_path), (preprocessed_img * 255).astype(np.uint8))\n",
    "    \n",
    "    # Adjust and save label\n",
    "    preprocessed_label_path = preprocessed_labels_dir / label_file.name\n",
    "    if label_file.stat().st_size > 0:\n",
    "        new_lines = adjust_label(label_file, scale, pad_left, pad_top, S, W, H)\n",
    "        with open(preprocessed_label_path, 'w') as f:\n",
    "            for line in new_lines:\n",
    "                f.write(line + '\\n')\n",
    "    else:\n",
    "        open(preprocessed_label_path, 'a').close()\n",
    "    \n",
    "    # Visualize samples\n",
    "    if plot_samples and label_file in sampled_images:\n",
    "        # Original image\n",
    "        img_original = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if label_file.stat().st_size > 0:\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    class_id, x_center_norm, y_center_norm, width_norm, height_norm = map(float, parts)\n",
    "                    xmin = int((x_center_norm - width_norm / 2) * W)\n",
    "                    ymin = int((y_center_norm - height_norm / 2) * H)\n",
    "                    xmax = int((x_center_norm + width_norm / 2) * W)\n",
    "                    ymax = int((y_center_norm + height_norm / 2) * H)\n",
    "                    cv2.rectangle(img_original, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(img_original)\n",
    "        plt.title(f\"Original: {image_file.name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # Preprocessed image\n",
    "        img_preprocessed = (preprocessed_img * 255).astype(np.uint8)\n",
    "        img_preprocessed = cv2.cvtColor(img_preprocessed, cv2.COLOR_BGR2RGB)\n",
    "        if label_file.stat().st_size > 0:\n",
    "            for line in new_lines:\n",
    "                parts = line.strip().split()\n",
    "                class_id, x_center_new, y_center_new, width_new, height_new = map(float, parts)\n",
    "                xmin = int((x_center_new - width_new / 2) * S)\n",
    "                ymin = int((y_center_new - height_new / 2) * S)\n",
    "                xmax = int((x_center_new + width_new / 2) * S)\n",
    "                ymax = int((y_center_new + height_new / 2) * S)\n",
    "                cv2.rectangle(img_preprocessed, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(img_preprocessed)\n",
    "        plt.title(f\"Preprocessed: {image_file.name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "logger.info(f\"Preprocessing completed. Total images processed: {len(selected_label_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the Preprocessed Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that the preprocessed dataset has no missing or corrupt data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_preprocessed_dataset():\n",
    "    image_files = set(f.stem for f in preprocessed_images_dir.glob('*.jpg'))\n",
    "    label_files = set(f.stem for f in preprocessed_labels_dir.glob('*.txt'))\n",
    "    \n",
    "    missing_labels = image_files - label_files\n",
    "    missing_images = label_files - image_files\n",
    "    \n",
    "    if missing_labels:\n",
    "        logger.warning(f\"Images missing labels: {len(missing_labels)} - {list(missing_labels)[:5]}\")\n",
    "    if missing_images:\n",
    "        logger.warning(f\"Labels missing images: {len(missing_images)} - {list(missing_images)[:5]}\")\n",
    "    else:\n",
    "        logger.info(\"Preprocessed dataset is complete: All images have corresponding labels and vice versa.\")\n",
    "    \n",
    "    logger.info(f\"Total preprocessed images: {len(image_files)}\")\n",
    "    logger.info(f\"Total preprocessed labels: {len(label_files)}\")\n",
    "\n",
    "verify_preprocessed_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigmaAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
