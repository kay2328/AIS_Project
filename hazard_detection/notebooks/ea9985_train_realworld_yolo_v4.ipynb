{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:14:43,816 - INFO - Random seeds set for reproducibility.\n"
     ]
    }
   ],
   "source": [
    "# --- Setup Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "logger.info(\"Random seeds set for reproducibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:14:43,825 - INFO - Directory structure created.\n"
     ]
    }
   ],
   "source": [
    "# --- Paths ---\n",
    "base_dir = Path('../datasets').resolve()\n",
    "cvat_dir = base_dir / 'cvat_upload'\n",
    "cvat_images_dir = cvat_dir / 'images'\n",
    "cvat_labels_dir = cvat_dir / 'labels'\n",
    "\n",
    "yolo_dir = Path('../yolo_cvat_v4').resolve()\n",
    "train_img_dir = yolo_dir / 'images' / 'train'\n",
    "val_img_dir = yolo_dir / 'images' / 'val'\n",
    "test_img_dir = yolo_dir / 'images' / 'test'  \n",
    "train_lbl_dir = yolo_dir / 'labels' / 'train'\n",
    "val_lbl_dir = yolo_dir / 'labels' / 'val'\n",
    "test_lbl_dir = yolo_dir / 'labels' / 'test' \n",
    "\n",
    "for d in [train_img_dir, val_img_dir, test_img_dir, train_lbl_dir, val_lbl_dir, test_lbl_dir]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "logger.info(\"Directory structure created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:14:43,868 - INFO - Found 0 images without labels.\n",
      "2025-04-11 11:14:43,870 - INFO - Collected 2681 images. Train: 1876, Val: 402, Test: 403\n"
     ]
    }
   ],
   "source": [
    "# --- Collect and Split Data ---\n",
    "images = list(cvat_images_dir.glob('*.jpg'))\n",
    "labels = list(cvat_labels_dir.glob('*.txt'))\n",
    "\n",
    "# Identify images without labels\n",
    "images_without_labels = [img for img in images if not (cvat_labels_dir / f\"{img.stem}.txt\").exists()]\n",
    "logger.info(f\"Found {len(images_without_labels)} images without labels.\")\n",
    "\n",
    "# Create empty label files for missing annotations\n",
    "for img in images_without_labels:\n",
    "    empty_lbl = cvat_labels_dir / f\"{img.stem}.txt\"\n",
    "    open(empty_lbl, 'w').close()\n",
    "    logger.info(f\"Created empty label file: {empty_lbl}\")\n",
    "\n",
    "# Split data into train, val, and test\n",
    "train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=42)  # 70% train, 30% temp\n",
    "val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)  # Split temp into 15% val, 15% test\n",
    "logger.info(f\"Collected {len(images)} images. Train: {len(train_imgs)}, Val: {len(val_imgs)}, Test: {len(test_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying to images: 100%|██████████| 1876/1876 [00:02<00:00, 655.89it/s]\n",
      "Copying to images: 100%|██████████| 402/402 [00:00<00:00, 745.58it/s]\n",
      "Copying to images: 100%|██████████| 403/403 [00:00<00:00, 740.73it/s]\n",
      "2025-04-11 11:14:47,827 - INFO - Data split and copied to train/val/test directories.\n"
     ]
    }
   ],
   "source": [
    "# Copy images and labels to train/val/test directories\n",
    "for split_imgs, img_dst, lbl_dst in [(train_imgs, train_img_dir, train_lbl_dir), \n",
    "                                     (val_imgs, val_img_dir, val_lbl_dir),\n",
    "                                     (test_imgs, test_img_dir, test_lbl_dir)]:\n",
    "    for img in tqdm(split_imgs, desc=f\"Copying to {img_dst.parent.name}\"):\n",
    "        lbl = cvat_labels_dir / f\"{img.stem}.txt\"\n",
    "        shutil.copy(img, img_dst / img.name)\n",
    "        if lbl.exists():\n",
    "            shutil.copy(lbl, lbl_dst / lbl.name)\n",
    "        else:\n",
    "            open(lbl_dst / f\"{img.stem}.txt\", 'w').close()\n",
    "logger.info(\"Data split and copied to train/val/test directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:14:47,834 - INFO - Defined classes: ['hole', 'pole', 'stairs', 'bottle', 'rock']\n"
     ]
    }
   ],
   "source": [
    "# --- Define Classes ---\n",
    "selected_classes = ['hole', 'pole', 'stairs', 'bottle', 'rock']\n",
    "logger.info(f\"Defined classes: {selected_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:14:47,931 - INFO - Collected bounding box statistics from training set.\n",
      "2025-04-11 11:14:47,933 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4941_00002.txt: 1 0.107852 0.255609 0.208672 0.508406 (class pole)\n",
      "2025-04-11 11:14:47,934 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00030.txt: 1 0.778164 0.206961 0.263359 0.413922 (class pole)\n",
      "2025-04-11 11:14:47,934 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00030.txt: 1 0.237406 0.647367 0.474000 0.705266 (class pole)\n",
      "2025-04-11 11:14:47,935 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4912_00009.txt: 1 0.961836 0.280055 0.076328 0.392297 (class pole)\n",
      "2025-04-11 11:14:47,937 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4982_00004.txt: 0 0.583570 0.447094 0.289078 0.546219 (class hole)\n",
      "2025-04-11 11:14:47,939 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4976_00004.txt: 4 0.396172 0.701719 0.791594 0.436969 (class rock)\n",
      "2025-04-11 11:14:47,941 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00034.txt: 1 0.188531 0.113500 0.189250 0.227000 (class pole)\n",
      "2025-04-11 11:14:47,942 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00034.txt: 1 0.107563 0.400703 0.214062 0.267250 (class pole)\n",
      "2025-04-11 11:14:47,943 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4953_00005.txt: 4 0.859602 0.343844 0.280797 0.684875 (class rock)\n",
      "2025-04-11 11:14:47,945 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4999_00003.txt: 1 0.851125 0.874945 0.297750 0.112047 (class pole)\n",
      "2025-04-11 11:14:47,946 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4979_00004.txt: 1 0.917180 0.217594 0.152953 0.433781 (class pole)\n",
      "2025-04-11 11:14:47,949 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4923_00020.txt: 1 0.867305 0.497914 0.265391 0.995797 (class pole)\n",
      "2025-04-11 11:14:47,950 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6529_00045.txt: 1 0.648820 0.217461 0.092359 0.434359 (class pole)\n",
      "2025-04-11 11:14:47,951 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5040_00006.txt: 3 0.445750 0.018289 0.125469 0.036578 (class bottle)\n",
      "2025-04-11 11:14:47,952 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00026.txt: 1 0.293633 0.096477 0.197578 0.191922 (class pole)\n",
      "2025-04-11 11:14:47,953 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00007.txt: 1 0.918625 0.887047 0.162594 0.225750 (class pole)\n",
      "2025-04-11 11:14:47,953 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5038_00008.txt: 3 0.811844 0.689641 0.136562 0.301125 (class bottle)\n",
      "2025-04-11 11:14:47,955 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4973_00006.txt: 4 0.372453 0.692039 0.744906 0.615922 (class rock)\n",
      "2025-04-11 11:14:47,955 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5040_00008.txt: 3 0.377039 0.849703 0.105359 0.296500 (class bottle)\n",
      "2025-04-11 11:14:47,956 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5042_00008.txt: 3 0.074508 0.750477 0.080734 0.296641 (class bottle)\n",
      "2025-04-11 11:14:47,958 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6530_00000.txt: 1 0.832977 0.259219 0.178484 0.517719 (class pole)\n",
      "2025-04-11 11:14:47,961 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4983_00005.txt: 0 0.639930 0.484883 0.718484 0.331922 (class hole)\n",
      "2025-04-11 11:14:47,961 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6531_00019.txt: 1 0.916992 0.192828 0.164172 0.385656 (class pole)\n",
      "2025-04-11 11:14:47,962 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6530_00020.txt: 1 0.524383 0.209172 0.029547 0.377594 (class pole)\n",
      "2025-04-11 11:14:47,964 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6529_00047.txt: 1 0.949898 0.217531 0.100203 0.435063 (class pole)\n",
      "2025-04-11 11:14:47,965 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6530_00024.txt: 1 0.406383 0.187836 0.046359 0.374891 (class pole)\n",
      "2025-04-11 11:14:47,967 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6530_00031.txt: 1 0.632078 0.209914 0.082906 0.418641 (class pole)\n",
      "2025-04-11 11:14:47,968 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4973_00005.txt: 4 0.380203 0.567664 0.709250 0.864672 (class rock)\n",
      "2025-04-11 11:14:47,969 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4981_00005.txt: 0 0.546586 0.274391 0.141172 0.548781 (class hole)\n",
      "2025-04-11 11:14:47,970 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6533_00003.txt: 1 0.424797 0.203781 0.057469 0.407562 (class pole)\n",
      "2025-04-11 11:14:47,972 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00001.txt: 1 0.867586 0.486906 0.264828 0.420594 (class pole)\n",
      "2025-04-11 11:14:47,973 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6461_00050.txt: 1 0.104328 0.233547 0.204250 0.462406 (class pole)\n",
      "2025-04-11 11:14:47,974 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4981_00007.txt: 0 0.623062 0.606766 0.233625 0.784875 (class hole)\n",
      "2025-04-11 11:14:47,975 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4946_00013.txt: 4 0.358547 0.399164 0.460781 0.795516 (class rock)\n",
      "2025-04-11 11:14:47,975 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5039_00004.txt: 3 0.201242 0.762531 0.335547 0.072938 (class bottle)\n",
      "2025-04-11 11:14:47,977 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5038_00025.txt: 3 0.489367 0.356312 0.086828 0.284312 (class bottle)\n",
      "2025-04-11 11:14:47,979 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4982_00005.txt: 0 0.635672 0.631133 0.460500 0.736141 (class hole)\n",
      "2025-04-11 11:14:47,981 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4956_00009.txt: 1 0.050945 0.741695 0.101891 0.516609 (class pole)\n",
      "2025-04-11 11:14:47,982 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00022.txt: 1 0.113539 0.394398 0.227078 0.740422 (class pole)\n",
      "2025-04-11 11:14:47,984 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00011.txt: 1 0.902094 0.467898 0.195813 0.327422 (class pole)\n",
      "2025-04-11 11:14:47,984 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6462_00116.txt: 2 0.500000 0.982859 1.000000 0.034281 (class stairs)\n",
      "2025-04-11 11:14:47,985 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6530_00030.txt: 1 0.632922 0.190789 0.081469 0.381016 (class pole)\n",
      "2025-04-11 11:14:47,987 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4976_00001.txt: 4 0.592828 0.684906 0.727781 0.406719 (class rock)\n",
      "2025-04-11 11:14:47,988 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6527_00006.txt: 1 0.880102 0.166750 0.167016 0.332906 (class pole)\n",
      "2025-04-11 11:14:47,990 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4915_00000.txt: 1 0.035648 0.332570 0.070172 0.410516 (class pole)\n",
      "2025-04-11 11:14:47,991 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6460_00019.txt: 1 0.845766 0.153742 0.167406 0.307422 (class pole)\n",
      "2025-04-11 11:14:47,992 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4941_00003.txt: 1 0.068984 0.553227 0.137969 0.663859 (class pole)\n",
      "2025-04-11 11:14:47,993 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00000.txt: 1 0.860922 0.248094 0.278156 0.495563 (class pole)\n",
      "2025-04-11 11:14:47,994 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5037_00002.txt: 3 0.596234 0.211320 0.138594 0.316109 (class bottle)\n",
      "2025-04-11 11:14:47,995 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4981_00006.txt: 0 0.575156 0.500039 0.238656 0.998328 (class hole)\n",
      "2025-04-11 11:14:47,997 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6531_00020.txt: 1 0.623578 0.134961 0.158688 0.268828 (class pole)\n",
      "2025-04-11 11:14:47,998 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6461_00044.txt: 1 0.907867 0.130711 0.182984 0.259578 (class pole)\n",
      "2025-04-11 11:14:47,999 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5040_00014.txt: 3 0.715555 0.842422 0.106203 0.312781 (class bottle)\n",
      "2025-04-11 11:14:48,000 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4923_00019.txt: 1 0.729000 0.274531 0.173656 0.546250 (class pole)\n",
      "2025-04-11 11:14:48,001 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4983_00004.txt: 0 0.655750 0.185867 0.688500 0.274516 (class hole)\n",
      "2025-04-11 11:14:48,002 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5038_00026.txt: 3 0.350820 0.683750 0.114766 0.309281 (class bottle)\n",
      "2025-04-11 11:14:48,002 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00005.txt: 1 0.853750 0.243523 0.292500 0.487047 (class pole)\n",
      "2025-04-11 11:14:48,004 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6461_00049.txt: 1 0.196539 0.183906 0.184422 0.363125 (class pole)\n",
      "2025-04-11 11:14:48,005 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00025.txt: 1 0.233359 0.057742 0.173906 0.115453 (class pole)\n",
      "2025-04-11 11:14:48,007 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00033.txt: 1 0.290102 0.179969 0.242141 0.359812 (class pole)\n",
      "2025-04-11 11:14:48,007 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00033.txt: 1 0.401641 0.074867 0.162875 0.149734 (class pole)\n",
      "2025-04-11 11:14:48,009 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4977_00006.txt: 4 0.621195 0.172711 0.757609 0.345422 (class rock)\n",
      "2025-04-11 11:14:48,010 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6530_00023.txt: 1 0.429375 0.189242 0.050000 0.378484 (class pole)\n",
      "2025-04-11 11:14:48,011 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00016.txt: 1 0.885992 0.255039 0.228016 0.490922 (class pole)\n",
      "2025-04-11 11:14:48,012 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4941_00012.txt: 1 0.105047 0.354352 0.208687 0.705891 (class pole)\n",
      "2025-04-11 11:14:48,013 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00029.txt: 1 0.873578 0.152531 0.230500 0.302594 (class pole)\n",
      "2025-04-11 11:14:48,013 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00029.txt: 1 0.383617 0.331609 0.347516 0.660750 (class pole)\n",
      "2025-04-11 11:14:48,014 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6530_00021.txt: 1 0.502453 0.190008 0.063844 0.379078 (class pole)\n",
      "2025-04-11 11:14:48,015 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00017.txt: 1 0.882117 0.523047 0.235766 0.396094 (class pole)\n",
      "2025-04-11 11:14:48,016 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5039_00003.txt: 3 0.583469 0.696586 0.259687 0.074891 (class bottle)\n",
      "2025-04-11 11:14:48,017 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4948_00011.txt: 4 0.270625 0.649164 0.541250 0.696078 (class rock)\n",
      "2025-04-11 11:14:48,018 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4982_00006.txt: 0 0.634828 0.704242 0.468906 0.586547 (class hole)\n",
      "2025-04-11 11:14:48,021 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6529_00042.txt: 1 0.514813 0.198516 0.079344 0.397031 (class pole)\n",
      "2025-04-11 11:14:48,022 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6533_00001.txt: 1 0.479383 0.225195 0.183328 0.449422 (class pole)\n",
      "2025-04-11 11:14:48,022 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4320_00004.txt: 1 0.733031 0.181547 0.212688 0.363094 (class pole)\n",
      "2025-04-11 11:14:48,023 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4946_00014.txt: 4 0.293078 0.579844 0.583344 0.837531 (class rock)\n",
      "2025-04-11 11:14:48,024 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6460_00020.txt: 1 0.903992 0.166336 0.189797 0.332609 (class pole)\n",
      "2025-04-11 11:14:48,026 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6530_00035.txt: 1 0.940727 0.254484 0.118547 0.458031 (class pole)\n",
      "2025-04-11 11:14:48,026 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6533_00000.txt: 1 0.053195 0.356148 0.099297 0.622922 (class pole)\n",
      "2025-04-11 11:14:48,027 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6533_00000.txt: 1 0.453188 0.227773 0.182031 0.443266 (class pole)\n",
      "2025-04-11 11:14:48,028 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4947_00014.txt: 4 0.842094 0.595242 0.315812 0.809516 (class rock)\n",
      "2025-04-11 11:14:48,028 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5038_00036.txt: 3 0.737016 0.839703 0.076187 0.319344 (class bottle)\n",
      "2025-04-11 11:14:48,030 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00028.txt: 1 0.416672 0.222211 0.272281 0.442234 (class pole)\n",
      "2025-04-11 11:14:48,030 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00028.txt: 1 0.849023 0.106273 0.197797 0.211484 (class pole)\n",
      "2025-04-11 11:14:48,032 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00027.txt: 1 0.733500 0.069641 0.170063 0.139281 (class pole)\n",
      "2025-04-11 11:14:48,032 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00027.txt: 1 0.339273 0.152031 0.227391 0.300438 (class pole)\n",
      "2025-04-11 11:14:48,033 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00031.txt: 1 0.518875 0.287148 0.310281 0.572141 (class pole)\n",
      "2025-04-11 11:14:48,033 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4318_00031.txt: 1 0.775875 0.095047 0.181344 0.188875 (class pole)\n",
      "2025-04-11 11:14:48,035 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_5041_00008.txt: 3 0.192680 0.230125 0.383359 0.110219 (class bottle)\n",
      "2025-04-11 11:14:48,035 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_4983_00006.txt: 0 0.592305 0.837125 0.813734 0.324938 (class hole)\n",
      "2025-04-11 11:14:48,037 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6529_00046.txt: 1 0.826836 0.217891 0.116234 0.435781 (class pole)\n",
      "2025-04-11 11:14:48,038 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6461_00043.txt: 1 0.817797 0.078477 0.178719 0.156953 (class pole)\n",
      "2025-04-11 11:14:48,039 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train/frame_IMG_6529_00043.txt: 1 0.451336 0.213523 0.076609 0.427047 (class pole)\n",
      "2025-04-11 11:14:48,040 - INFO - Annotation check completed for /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train\n",
      "2025-04-11 11:14:48,041 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4921_00007.txt: 0 0.279414 0.576336 0.165266 0.704484 (class hole)\n",
      "2025-04-11 11:14:48,043 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4320_00006.txt: 1 0.871031 0.404898 0.257937 0.557453 (class pole)\n",
      "2025-04-11 11:14:48,044 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_5040_00013.txt: 3 0.763992 0.620078 0.095703 0.327969 (class bottle)\n",
      "2025-04-11 11:14:48,046 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4320_00010.txt: 1 0.612992 0.207852 0.204891 0.413703 (class pole)\n",
      "2025-04-11 11:14:48,047 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_6533_00004.txt: 1 0.354273 0.197859 0.047891 0.395719 (class pole)\n",
      "2025-04-11 11:14:48,048 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_6529_00044.txt: 1 0.493750 0.216773 0.074563 0.433547 (class pole)\n",
      "2025-04-11 11:14:48,049 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4318_00032.txt: 1 0.544195 0.130625 0.202547 0.261250 (class pole)\n",
      "2025-04-11 11:14:48,049 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4318_00032.txt: 1 0.213406 0.430391 0.425531 0.860781 (class pole)\n",
      "2025-04-11 11:14:48,050 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_5037_00013.txt: 3 0.483297 0.681906 0.088500 0.298594 (class bottle)\n",
      "2025-04-11 11:14:48,051 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4953_00006.txt: 4 0.897773 0.558836 0.203078 0.725484 (class rock)\n",
      "2025-04-11 11:14:48,052 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_6530_00033.txt: 1 0.778266 0.213359 0.123125 0.426031 (class pole)\n",
      "2025-04-11 11:14:48,054 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4320_00021.txt: 1 0.185039 0.260625 0.252953 0.519031 (class pole)\n",
      "2025-04-11 11:14:48,055 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4941_00008.txt: 1 0.068633 0.754211 0.135859 0.488797 (class pole)\n",
      "2025-04-11 11:14:48,056 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_5034_00002.txt: 3 0.878453 0.641133 0.098062 0.288547 (class bottle)\n",
      "2025-04-11 11:14:48,056 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_6530_00034.txt: 1 0.869141 0.220008 0.154312 0.439984 (class pole)\n",
      "2025-04-11 11:14:48,058 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_6530_00032.txt: 1 0.690680 0.213195 0.093578 0.425203 (class pole)\n",
      "2025-04-11 11:14:48,059 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_6530_00001.txt: 1 0.910937 0.268203 0.178125 0.536406 (class pole)\n",
      "2025-04-11 11:14:48,059 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4947_00004.txt: 4 0.149867 0.366258 0.295516 0.679266 (class rock)\n",
      "2025-04-11 11:14:48,060 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4322_00048.txt: 1 0.897883 0.149836 0.168953 0.299672 (class pole)\n",
      "2025-04-11 11:14:48,063 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val/frame_IMG_4956_00008.txt: 1 0.069109 0.315648 0.132781 0.631297 (class pole)\n",
      "2025-04-11 11:14:48,064 - INFO - Annotation check completed for /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val\n",
      "2025-04-11 11:14:48,065 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_5041_00005.txt: 3 0.982789 0.821078 0.033766 0.027031 (class bottle)\n",
      "2025-04-11 11:14:48,070 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_4318_00024.txt: 1 0.221836 0.021727 0.157141 0.043297 (class pole)\n",
      "2025-04-11 11:14:48,072 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_4973_00004.txt: 4 0.415500 0.387344 0.594969 0.773281 (class rock)\n",
      "2025-04-11 11:14:48,073 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_5033_00007.txt: 3 0.468500 0.609930 0.077000 0.285297 (class bottle)\n",
      "2025-04-11 11:14:48,075 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_4948_00014.txt: 4 0.803234 0.616961 0.392156 0.757703 (class rock)\n",
      "2025-04-11 11:14:48,075 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_5037_00003.txt: 3 0.676359 0.519477 0.176031 0.398766 (class bottle)\n",
      "2025-04-11 11:14:48,077 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_4948_00013.txt: 4 0.775563 0.454484 0.448875 0.707281 (class rock)\n",
      "2025-04-11 11:14:48,078 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_5041_00007.txt: 3 0.577570 0.303367 0.306297 0.083484 (class bottle)\n",
      "2025-04-11 11:14:48,080 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_4956_00007.txt: 1 0.147070 0.212125 0.091047 0.418906 (class pole)\n",
      "2025-04-11 11:14:48,080 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_4941_00007.txt: 1 0.136563 0.279422 0.184875 0.558812 (class pole)\n",
      "2025-04-11 11:14:48,081 - WARNING - Potential mislabel in /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test/frame_IMG_6533_00002.txt: 1 0.500117 0.214188 0.193859 0.428375 (class pole)\n",
      "2025-04-11 11:14:48,084 - INFO - Annotation check completed for /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test\n"
     ]
    }
   ],
   "source": [
    "# --- Annotation Validation Functions ---\n",
    "def collect_bbox_stats(label_dir, class_names):\n",
    "    \"\"\"Collect bounding box width and height statistics per class.\"\"\"\n",
    "    class_bboxes = defaultdict(list)\n",
    "    for lbl_file in label_dir.glob('*.txt'):\n",
    "        with open(lbl_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                parts = line.split()\n",
    "                try:\n",
    "                    cls_id = int(parts[0])\n",
    "                    if cls_id >= len(class_names) or cls_id < 0:\n",
    "                        logger.warning(f\"Skipping invalid class ID {cls_id} in {lbl_file}\")\n",
    "                        continue\n",
    "                    width = float(parts[3])\n",
    "                    height = float(parts[4])\n",
    "                    class_bboxes[cls_id].append((width, height))\n",
    "                except ValueError:\n",
    "                    logger.error(f\"Invalid values in {lbl_file}: {line}\")\n",
    "    return class_bboxes\n",
    "\n",
    "def compute_bbox_stats(class_bboxes):\n",
    "    \"\"\"Compute mean and std of bbox dimensions per class.\"\"\"\n",
    "    stats = {}\n",
    "    for cls_id, bboxes in class_bboxes.items():\n",
    "        if bboxes:\n",
    "            widths = [w for w, h in bboxes]\n",
    "            heights = [h for w, h in bboxes]\n",
    "            stats[cls_id] = {\n",
    "                'mean_w': np.mean(widths), 'std_w': np.std(widths),\n",
    "                'mean_h': np.mean(heights), 'std_h': np.std(heights)\n",
    "            }\n",
    "        else:\n",
    "            stats[cls_id] = {'mean_w': 0, 'std_w': 0, 'mean_h': 0, 'std_h': 0}\n",
    "    return stats\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute Intersection over Union between two bounding boxes.\"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    x1_min, x1_max = x1 - w1 / 2, x1 + w1 / 2\n",
    "    y1_min, y1_max = y1 - h1 / 2, y1 + h1 / 2\n",
    "    x2_min, x2_max = x2 - w2 / 2, x2 + w2 / 2\n",
    "    y2_min, y2_max = y2 - h2 / 2, y2 + h2 / 2\n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "    inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def check_annotations(label_dir, class_names, stats, iou_threshold=0.9, size_threshold=2):\n",
    "    \"\"\"Validate annotations for errors: invalid IDs, duplicates, size anomalies.\"\"\"\n",
    "    mislabel_images = []\n",
    "    for lbl_file in label_dir.glob('*.txt'):\n",
    "        with open(lbl_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        boxes = []\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                parts = line.split()\n",
    "                if len(parts) != 5:\n",
    "                    logger.error(f\"Invalid format in {lbl_file}: {line}\")\n",
    "                    continue\n",
    "                try:\n",
    "                    cls_id = int(parts[0])\n",
    "                    x, y, w, h = map(float, parts[1:])\n",
    "                except ValueError:\n",
    "                    logger.error(f\"Invalid values in {lbl_file}: {line}\")\n",
    "                    continue\n",
    "                if cls_id >= len(class_names) or cls_id < 0:\n",
    "                    logger.error(f\"Invalid class ID {cls_id} in {lbl_file}\")\n",
    "                    continue\n",
    "                if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
    "                    logger.error(f\"Out-of-range value in {lbl_file}: {line}\")\n",
    "                    continue\n",
    "                boxes.append((cls_id, x, y, w, h))\n",
    "                if cls_id in stats and stats[cls_id]['std_w'] > 0 and stats[cls_id]['std_h'] > 0:\n",
    "                    mean_w, std_w = stats[cls_id]['mean_w'], stats[cls_id]['std_w']\n",
    "                    mean_h, std_h = stats[cls_id]['mean_h'], stats[cls_id]['std_h']\n",
    "                    if abs(w - mean_w) > size_threshold * std_w or abs(h - mean_h) > size_threshold * std_h:\n",
    "                        logger.warning(f\"Potential mislabel in {lbl_file}: {line.strip()} (class {class_names[cls_id]})\")\n",
    "                        mislabel_images.append(lbl_file.stem)\n",
    "        for i in range(len(boxes)):\n",
    "            for j in range(i + 1, len(boxes)):\n",
    "                box1 = boxes[i][1:]\n",
    "                box2 = boxes[j][1:]\n",
    "                iou = compute_iou(box1, box2)\n",
    "                if iou > iou_threshold:\n",
    "                    logger.warning(f\"High IoU ({iou:.2f}) in {lbl_file}: {boxes[i]} and {boxes[j]}\")\n",
    "                    mislabel_images.append(lbl_file.stem)\n",
    "    logger.info(f\"Annotation check completed for {label_dir}\")\n",
    "    return list(set(mislabel_images))\n",
    "\n",
    "# --- Visualize Annotations ---\n",
    "def visualize_annotations(image_path, label_path, class_names):\n",
    "    \"\"\"Visualize bounding boxes on an image.\"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        logger.error(f\"Failed to load image: {image_path}\")\n",
    "        return None\n",
    "    h, w = img.shape[:2]\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                cls_id, x, y, width, height = map(float, line.split())\n",
    "                x1 = int((x - width / 2) * w)\n",
    "                y1 = int((y - height / 2) * h)\n",
    "                x2 = int((x + width / 2) * w)\n",
    "                y2 = int((y + height / 2) * h)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                label = class_names[int(cls_id)]\n",
    "                cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def plot_samples_per_class(image_dir, label_dir, class_names, num_samples=3, output_dir='sample_visualizations'):\n",
    "    \"\"\"Plot sample images with annotations for each class and save to output_dir.\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    class_images = {i: [] for i in range(len(class_names))}\n",
    "    for lbl_file in label_dir.glob('*.txt'):\n",
    "        with open(lbl_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        classes_in_image = set()\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                cls_id = int(line.split()[0])\n",
    "                classes_in_image.add(cls_id)\n",
    "        for c_id in classes_in_image:\n",
    "            class_images[c_id].append(lbl_file.stem)\n",
    "    \n",
    "    for cls_id, stems in class_images.items():\n",
    "        if not stems:\n",
    "            logger.warning(f\"No images found for class {class_names[cls_id]} in {label_dir}\")\n",
    "            continue\n",
    "        selected_stems = random.sample(stems, min(num_samples, len(stems)))\n",
    "        for s in selected_stems:\n",
    "            img_path = image_dir / f\"{s}.jpg\"\n",
    "            lbl_path = label_dir / f\"{s}.txt\"\n",
    "            annotated = visualize_annotations(img_path, lbl_path, class_names)\n",
    "            if annotated is not None:\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.imshow(annotated)\n",
    "                plt.title(f\"{class_names[cls_id]} - {s}\")\n",
    "                plt.axis('off')\n",
    "                safe_class_name = class_names[cls_id].replace(\"/\", \"_\")\n",
    "                plt.savefig(output_path / f\"{safe_class_name}_{s}.png\")\n",
    "                plt.close()\n",
    "    logger.info(f\"Saved annotation visualizations for {label_dir.parent.name} in '{output_dir}'.\")\n",
    "\n",
    "def visualize_mislabels(image_dir, label_dir, class_names, mislabel_stems, output_dir='mislabels'):\n",
    "    \"\"\"Visualize images with potential mislabels and save them to a folder.\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for stem in mislabel_stems:\n",
    "        img_path = image_dir / f\"{stem}.jpg\"\n",
    "        lbl_path = label_dir / f\"{stem}.txt\"\n",
    "        if img_path.exists() and lbl_path.exists():\n",
    "            annotated = visualize_annotations(img_path, lbl_path, class_names)\n",
    "            if annotated is not None:\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.imshow(annotated)\n",
    "                plt.title(f\"Potential Mislabel - {stem}\")\n",
    "                plt.axis('off')\n",
    "                plt.savefig(output_path / f\"{stem}.png\")\n",
    "                plt.close()\n",
    "    logger.info(f\"Saved visualizations of potential mislabels in '{output_dir}'.\")\n",
    "\n",
    "# Collect stats and check annotations\n",
    "train_class_bboxes = collect_bbox_stats(train_lbl_dir, selected_classes)\n",
    "train_stats = compute_bbox_stats(train_class_bboxes)\n",
    "logger.info(\"Collected bounding box statistics from training set.\")\n",
    "train_mislabels = check_annotations(train_lbl_dir, selected_classes, train_stats)\n",
    "val_mislabels = check_annotations(val_lbl_dir, selected_classes, train_stats)\n",
    "test_mislabels = check_annotations(test_lbl_dir, selected_classes, train_stats)  # Check test set too\n",
    "all_mislabels = list(set(train_mislabels + val_mislabels + test_mislabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:14:48,257 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:48,394 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:48,533 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:48,681 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:48,822 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:48,953 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:49,092 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:49,243 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:49,383 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:49,528 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:49,658 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:49,792 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:49,929 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:50,062 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:50,281 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:50,438 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:50,571 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:50,711 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:50,853 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:50,991 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:51,126 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:51,263 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:51,410 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:51,548 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:51,681 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:51,814 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:51,954 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:52,082 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:52,222 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:52,356 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:52,495 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:52,633 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:52,803 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:52,932 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:53,072 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:53,212 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:53,350 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:53,474 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:53,606 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:53,735 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:53,870 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:54,006 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:54,168 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:54,304 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:54,454 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:54,588 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:54,721 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:54,856 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:54,998 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:55,138 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:55,276 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:55,408 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:55,539 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:55,772 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:55,913 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:56,069 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:56,204 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:56,339 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:56,479 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:56,611 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:56,752 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:56,888 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:57,024 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:57,154 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:57,288 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:57,427 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:57,558 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:57,690 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:57,822 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:57,958 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:58,097 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:58,274 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:58,409 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:58,552 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:58,690 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:58,831 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:58,963 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:59,100 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:59,240 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:59,372 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:59,511 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:59,648 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:59,789 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:14:59,921 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:00,054 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:00,183 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:00,317 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:00,452 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:00,589 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:00,725 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:00,872 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:01,012 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:01,146 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:01,271 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:01,409 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:01,541 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:01,681 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:01,824 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:01,961 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:02,096 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:02,231 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:02,493 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:02,629 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:02,761 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:02,897 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:03,044 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:03,180 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:03,317 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:03,465 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:03,597 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:03,731 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:03,868 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:04,004 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:04,145 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n",
      "2025-04-11 11:15:04,279 - INFO - Saved visualizations of potential mislabels in 'mislabels'.\n"
     ]
    }
   ],
   "source": [
    "# Visualize all mislabels\n",
    "def get_image_label_dirs(stem):\n",
    "    if (train_img_dir / f\"{stem}.jpg\").exists():\n",
    "        return train_img_dir, train_lbl_dir\n",
    "    elif (val_img_dir / f\"{stem}.jpg\").exists():\n",
    "        return val_img_dir, val_lbl_dir\n",
    "    elif (test_img_dir / f\"{stem}.jpg\").exists():  # Include test set\n",
    "        return test_img_dir, test_lbl_dir\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "for stem in all_mislabels:\n",
    "    img_dir, lbl_dir = get_image_label_dirs(stem)\n",
    "    if img_dir and lbl_dir:\n",
    "        visualize_mislabels(img_dir, lbl_dir, selected_classes, [stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:15:04,358 - INFO - Train class counts: {4: 100, 1: 872, 3: 142, 2: 118, 0: 92}\n",
      "2025-04-11 11:15:04,358 - INFO - Val class counts: {0: 12, 1: 195, 3: 21, 2: 27, 4: 12}\n",
      "2025-04-11 11:15:04,359 - INFO - Test class counts: {0: 12, 1: 131, 3: 27, 4: 17, 2: 35}\n",
      "2025-04-11 11:15:04,473 - INFO - Saved class distribution plot to 'class_distribution.png'.\n"
     ]
    }
   ],
   "source": [
    "# --- Class Distribution ---\n",
    "def get_class_counts(label_dir):\n",
    "    \"\"\"Count instances per class in label files.\"\"\"\n",
    "    class_counts = Counter()\n",
    "    for lbl_file in label_dir.glob('*.txt'):\n",
    "        with open(lbl_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                cls_id = int(line.split()[0])\n",
    "                class_counts[cls_id] += 1\n",
    "    return class_counts\n",
    "\n",
    "train_class_counts = get_class_counts(train_lbl_dir)\n",
    "val_class_counts = get_class_counts(val_lbl_dir)\n",
    "test_class_counts = get_class_counts(test_lbl_dir)  # Count test set classes\n",
    "logger.info(f\"Train class counts: {dict(train_class_counts)}\")\n",
    "logger.info(f\"Val class counts: {dict(val_class_counts)}\")\n",
    "logger.info(f\"Test class counts: {dict(test_class_counts)}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(selected_classes, [train_class_counts.get(i, 0) for i in range(len(selected_classes))], \n",
    "        alpha=0.5, label='Train')\n",
    "plt.bar(selected_classes, [val_class_counts.get(i, 0) for i in range(len(selected_classes))], \n",
    "        alpha=0.5, label='Val')\n",
    "plt.bar(selected_classes, [test_class_counts.get(i, 0) for i in range(len(selected_classes))], \n",
    "        alpha=0.5, label='Test')  # Include test set in plot\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.title('Class Distribution')\n",
    "plt.legend()\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.close()\n",
    "logger.info(\"Saved class distribution plot to 'class_distribution.png'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize Test Set Predictions ---\n",
    "def visualize_predictions(model, image_dir, label_dir, class_names, num_samples=5, output_dir='test_predictions'):\n",
    "    \"\"\"Visualize model predictions on test set images with ground truth and predictions.\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_images = list(image_dir.glob('*.jpg'))\n",
    "    selected_images = random.sample(test_images, min(num_samples, len(test_images)))\n",
    "    \n",
    "    for img_path in selected_images:\n",
    "        # Load image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            logger.error(f\"Failed to load image: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Get ground truth annotations\n",
    "        lbl_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        gt_boxes = []\n",
    "        if lbl_path.exists():\n",
    "            with open(lbl_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        cls_id, x, y, w, h = map(float, line.split())\n",
    "                        gt_boxes.append((int(cls_id), x, y, w, h))\n",
    "        \n",
    "        # Run inference\n",
    "        results = model(img_path)\n",
    "        \n",
    "        # Plot ground truth and predictions\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Ground truth\n",
    "        ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax[0].set_title(\"Ground Truth\")\n",
    "        h, w = img.shape[:2]\n",
    "        for cls_id, x, y, width, height in gt_boxes:\n",
    "            x1 = int((x - width / 2) * w)\n",
    "            y1 = int((y - height / 2) * h)\n",
    "            x2 = int((x + width / 2) * w)\n",
    "            y2 = int((y + height / 2) * h)\n",
    "            ax[0].add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='green', facecolor='none', lw=2))\n",
    "            ax[0].text(x1, y1 - 10, class_names[int(cls_id)], color='green', fontsize=12)\n",
    "        \n",
    "        # Predictions\n",
    "        pred_img = results[0].plot()  # Plot predictions on the image\n",
    "        ax[1].imshow(pred_img)\n",
    "        ax[1].set_title(\"Predictions\")\n",
    "        \n",
    "        # Save figure\n",
    "        plt.savefig(output_path / f\"{img_path.stem}_pred.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    logger.info(f\"Saved test set prediction visualizations in '{output_dir}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 11:15:04,492 - INFO - Created data.yaml at /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# --- Create YOLO data.yaml ---\n",
    "data_yaml_path = yolo_dir / 'data.yaml'\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    f.write(f\"train: {train_img_dir.resolve()}\\n\")\n",
    "    f.write(f\"val: {val_img_dir.resolve()}\\n\")\n",
    "    f.write(f\"test: {test_img_dir.resolve()}\\n\")  \n",
    "    f.write(f\"nc: {len(selected_classes)}\\n\")\n",
    "    f.write(f\"names: {selected_classes}\\n\")\n",
    "logger.info(f\"Created data.yaml at {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:02:16,038 - INFO - Initialized YOLOv8s model from pretrained weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.107 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.105 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 with Max-Q Design, 7959MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/home/r0jin/projects/EnigmaAI/yolo_cvat_v4/data.yaml, epochs=100, time=None, patience=10, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=runs/train, name=cvat_v4_smoother, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0003, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.005, hsv_s=0.3, hsv_v=0.2, degrees=5, translate=0.05, scale=0.1, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0, mixup=0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/train/cvat_v4_smoother\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117983  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,137,535 parameters, 11,137,519 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train/cvat_v4_smoother', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/train.cache... 1876 images, 1218 backgrounds, 0 corrupt: 100%|██████████| 1876/1876 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val.cache... 402 images, 269 backgrounds, 0 corrupt: 100%|██████████| 402/402 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/train/cvat_v4_smoother/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0003' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/cvat_v4_smoother\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      1.95G       1.57      9.311      1.444          2        640: 100%|██████████| 235/235 [00:34<00:00,  6.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267       0.81      0.237      0.248      0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      2.22G      1.886      3.287      1.725          1        640: 100%|██████████| 235/235 [00:33<00:00,  6.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.586      0.156       0.18     0.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      2.22G      1.998      3.122      1.823          1        640: 100%|██████████| 235/235 [00:33<00:00,  7.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.284     0.0598     0.0445       0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      2.23G      1.932      2.936      1.791          0        640: 100%|██████████| 235/235 [00:33<00:00,  7.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.592      0.268      0.204      0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      2.23G      1.946      2.856      1.856          2        640: 100%|██████████| 235/235 [00:33<00:00,  7.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.702      0.213      0.234      0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      2.23G      1.874      2.613      1.766          7        640: 100%|██████████| 235/235 [00:34<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.681      0.221      0.254      0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      2.23G      1.817      2.495      1.723          2        640: 100%|██████████| 235/235 [00:34<00:00,  6.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.739      0.334      0.402      0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      2.23G      1.688      2.291      1.593          2        640: 100%|██████████| 235/235 [00:34<00:00,  6.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.856      0.238       0.35      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      2.23G      1.644      2.263       1.57          3        640: 100%|██████████| 235/235 [00:34<00:00,  6.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.395      0.425      0.407        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      2.23G      1.636      2.146      1.537          0        640: 100%|██████████| 235/235 [00:34<00:00,  6.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.698      0.346       0.38      0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      2.23G      1.614      2.216      1.577          5        640: 100%|██████████| 235/235 [00:34<00:00,  6.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.689      0.297      0.363       0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      2.23G      1.585      2.143      1.545          0        640: 100%|██████████| 235/235 [00:34<00:00,  6.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.682      0.353       0.39      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      2.23G      1.514      2.052      1.511          6        640: 100%|██████████| 235/235 [00:34<00:00,  6.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.801      0.361      0.397      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      2.23G      1.537      1.962      1.505          2        640: 100%|██████████| 235/235 [00:34<00:00,  6.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.819      0.359      0.437      0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      2.23G      1.529      1.835      1.497          6        640: 100%|██████████| 235/235 [00:36<00:00,  6.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.795      0.332      0.431      0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      2.23G       1.43      1.729      1.425          1        640: 100%|██████████| 235/235 [00:34<00:00,  6.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267       0.69      0.381      0.436      0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      2.23G      1.503      1.718      1.441          0        640: 100%|██████████| 235/235 [00:35<00:00,  6.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.578       0.39       0.41      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      2.23G      1.405      1.643       1.41          0        640: 100%|██████████| 235/235 [00:35<00:00,  6.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.766      0.365      0.462      0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      2.23G       1.43      1.657      1.438          1        640: 100%|██████████| 235/235 [00:33<00:00,  7.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.731      0.411      0.484      0.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      2.23G      1.403      1.645      1.401          3        640: 100%|██████████| 235/235 [00:34<00:00,  6.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.309      0.443       0.43      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      2.23G      1.372      1.509      1.373          2        640: 100%|██████████| 235/235 [00:34<00:00,  6.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.711       0.43      0.454      0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      2.23G      1.389      1.477      1.412          7        640: 100%|██████████| 235/235 [00:33<00:00,  7.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.332      0.415      0.446      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      2.23G      1.316      1.486      1.353          3        640: 100%|██████████| 235/235 [00:29<00:00,  7.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267       0.79      0.393      0.482      0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      2.23G      1.315      1.415      1.344          1        640: 100%|██████████| 235/235 [00:29<00:00,  7.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267       0.38      0.496      0.465      0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      2.23G      1.312      1.378      1.335          7        640: 100%|██████████| 235/235 [00:29<00:00,  7.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  9.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.441      0.533      0.497      0.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      2.23G      1.329      1.363      1.349          6        640: 100%|██████████| 235/235 [00:29<00:00,  7.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.603      0.518      0.489      0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      2.23G      1.302      1.448      1.317          2        640: 100%|██████████| 235/235 [00:29<00:00,  7.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267       0.66      0.512      0.531      0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      2.23G       1.26      1.337      1.277          0        640: 100%|██████████| 235/235 [00:29<00:00,  7.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.361      0.577      0.507        0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      2.23G      1.222      1.317      1.252          1        640: 100%|██████████| 235/235 [00:29<00:00,  7.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.678       0.42      0.519      0.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      2.23G      1.215      1.304       1.27          6        640: 100%|██████████| 235/235 [00:33<00:00,  7.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.579      0.557      0.535      0.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      2.23G      1.201      1.189      1.271          1        640: 100%|██████████| 235/235 [00:34<00:00,  6.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267       0.46      0.525      0.509      0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      2.23G      1.232      1.245       1.29          5        640: 100%|██████████| 235/235 [00:34<00:00,  6.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.514      0.461        0.5      0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      2.23G      1.204       1.23      1.274          1        640: 100%|██████████| 235/235 [00:34<00:00,  6.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.543      0.616      0.579      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      2.23G      1.178      1.208      1.245          1        640: 100%|██████████| 235/235 [00:34<00:00,  6.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.513       0.55      0.531      0.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      2.23G      1.197      1.227      1.252          1        640: 100%|██████████| 235/235 [00:33<00:00,  6.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.728      0.505      0.595      0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      2.23G      1.112      1.063      1.189          2        640: 100%|██████████| 235/235 [00:33<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267       0.55      0.557      0.545      0.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      2.23G      1.146      1.073      1.236          5        640: 100%|██████████| 235/235 [00:33<00:00,  7.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.567       0.51      0.533      0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      2.23G      1.169       1.05       1.25          5        640: 100%|██████████| 235/235 [00:33<00:00,  7.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.682      0.578      0.607      0.382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      2.23G       1.12      1.076      1.209          3        640: 100%|██████████| 235/235 [00:33<00:00,  6.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.699      0.577      0.657      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      2.23G      1.143      1.149      1.193          0        640: 100%|██████████| 235/235 [00:34<00:00,  6.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.568      0.659      0.615      0.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      2.23G      1.106      1.053      1.208          1        640: 100%|██████████| 235/235 [00:33<00:00,  7.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.617      0.544      0.571      0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      2.23G      1.071       1.03      1.169          5        640: 100%|██████████| 235/235 [00:32<00:00,  7.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.819      0.533      0.607      0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      2.23G      1.116      1.012      1.179          1        640: 100%|██████████| 235/235 [00:35<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.732      0.564      0.597      0.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      2.23G      1.114     0.9862      1.199          0        640: 100%|██████████| 235/235 [00:32<00:00,  7.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.672      0.625      0.689      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      2.23G      1.085     0.9346      1.179          2        640: 100%|██████████| 235/235 [00:35<00:00,  6.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.644      0.679      0.678      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      2.23G      1.099     0.9729      1.184          3        640: 100%|██████████| 235/235 [00:32<00:00,  7.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.701      0.567      0.625      0.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      2.23G      1.076     0.9529      1.165          4        640: 100%|██████████| 235/235 [00:33<00:00,  6.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.672      0.622       0.67      0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      2.23G      1.068     0.9028      1.157          7        640: 100%|██████████| 235/235 [00:34<00:00,  6.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.689      0.681      0.721      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      2.23G      1.061     0.8765      1.162          0        640: 100%|██████████| 235/235 [00:34<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.647      0.648      0.641      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      2.23G      1.033     0.8345      1.138          1        640: 100%|██████████| 235/235 [00:32<00:00,  7.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.693      0.722      0.719      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      2.23G      1.058     0.8726       1.16          0        640: 100%|██████████| 235/235 [00:29<00:00,  7.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.656       0.71      0.661      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      2.23G      1.036     0.8941      1.148          1        640: 100%|██████████| 235/235 [00:29<00:00,  7.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.573      0.684      0.604      0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      2.23G      1.013     0.8655      1.135          0        640: 100%|██████████| 235/235 [00:31<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:02<00:00,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.713      0.521      0.605      0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      2.23G      0.977     0.8723      1.121          3        640: 100%|██████████| 235/235 [00:34<00:00,  6.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.739      0.627      0.678      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      2.23G     0.9895     0.8205      1.107          0        640: 100%|██████████| 235/235 [00:34<00:00,  6.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.645      0.128      0.132     0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      2.23G     0.9878     0.7849      1.111          2        640: 100%|██████████| 235/235 [00:34<00:00,  6.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.662      0.626       0.66      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      2.23G      1.016     0.8589      1.139          2        640: 100%|██████████| 235/235 [00:37<00:00,  6.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.706      0.638      0.708      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      2.23G      1.015     0.8037      1.143          2        640: 100%|██████████| 235/235 [00:34<00:00,  6.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.658       0.76      0.688      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      2.23G     0.9804     0.8396      1.117          1        640: 100%|██████████| 235/235 [00:34<00:00,  6.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.788      0.618      0.703       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      2.23G     0.9985     0.7935      1.122          2        640: 100%|██████████| 235/235 [00:36<00:00,  6.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:03<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.689      0.677      0.703      0.458\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 50, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "60 epochs completed in 0.619 hours.\n",
      "Optimizer stripped from runs/train/cvat_v4_smoother/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/train/cvat_v4_smoother/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/train/cvat_v4_smoother/weights/best.pt...\n",
      "Ultralytics 8.3.105 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 with Max-Q Design, 7959MiB)\n",
      "Model summary (fused): 72 layers, 11,127,519 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 26/26 [00:07<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267      0.672      0.753      0.736      0.469\n",
      "                  hole          9         12      0.628      0.583      0.512      0.247\n",
      "                  pole         76        195      0.739      0.821       0.85      0.515\n",
      "                stairs         25         27      0.559      0.741      0.713      0.436\n",
      "                bottle         16         21      0.846      0.952      0.953      0.733\n",
      "                  rock          9         12      0.587      0.667      0.651      0.415\n",
      "Speed: 0.3ms preprocess, 14.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/cvat_v4_smoother\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- Train YOLOv8 Model ---\n",
    "model = YOLO('yolov8s.pt')\n",
    "logger.info(\"Initialized YOLOv8s model from pretrained weights.\")\n",
    "\n",
    "results = model.train(\n",
    "    data=str(data_yaml_path),\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    lr0=0.0003,\n",
    "    warmup_epochs=3,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    name=\"cvat_v4_smoother\",\n",
    "    project=\"runs/train\",\n",
    "    patience=10,\n",
    "    verbose=True,\n",
    "    plots=True,\n",
    "    augment=True,\n",
    "    mosaic=0,\n",
    "    mixup=0,\n",
    "    degrees=5,\n",
    "    translate=0.05,\n",
    "    scale=0.1,\n",
    "    shear=0.0,\n",
    "    hsv_h=0.005,             # lower color jitter\n",
    "    hsv_s=0.3,\n",
    "    hsv_v=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:39:41,716 - INFO - Training Metrics:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP50: 0.7358\n",
      "mAP50-95: 0.4691\n",
      "Precision: 0.6717\n",
      "Recall: 0.7527\n",
      "hole - mAP50: 0.2466\n",
      "pole - mAP50: 0.5153\n",
      "stairs - mAP50: 0.4356\n",
      "bottle - mAP50: 0.7329\n",
      "rock - mAP50: 0.4152\n"
     ]
    }
   ],
   "source": [
    "# --- Print Training Metrics ---\n",
    "logger.info(\"Training Metrics:\")\n",
    "print(f\"mAP50: {results.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {results.box.map:.4f}\")\n",
    "print(f\"Precision: {np.mean(results.box.p):.4f}\")\n",
    "print(f\"Recall: {np.mean(results.box.r):.4f}\")\n",
    "for i, cls in enumerate(selected_classes):\n",
    "    print(f\"{cls} - mAP50: {results.box.maps[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.105 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 with Max-Q Design, 7959MiB)\n",
      "Model summary (fused): 72 layers, 11,127,519 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/val.cache... 402 images, 269 backgrounds, 0 corrupt: 100%|██████████| 402/402 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:12<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        402        267       0.67      0.753      0.735      0.469\n",
      "                  hole          9         12      0.626      0.583      0.512      0.248\n",
      "                  pole         76        195      0.734      0.821      0.845      0.515\n",
      "                stairs         25         27      0.558      0.741      0.714      0.438\n",
      "                bottle         16         21      0.846      0.952      0.953      0.732\n",
      "                  rock          9         12      0.585      0.667      0.651      0.415\n",
      "Speed: 0.6ms preprocess, 27.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/cvat_v4_smoother2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:39:57,613 - INFO - Validation completed on validation set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Metrics:\n",
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0, 1, 2, 3, 4])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7531bc6a8f10>\n",
      "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
      "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.045977,    0.045977,           0],\n",
      "       [          1,           1,           1, ...,   0.0022002,   0.0011001,           0],\n",
      "       [          1,           1,           1, ...,   0.0010541,  0.00052705,           0],\n",
      "       [          1,           1,           1, ...,   0.0046455,   0.0023228,           0],\n",
      "       [          1,           1,           1, ...,  0.00051214,  0.00025607,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.033287,    0.033287,    0.048995, ...,           0,           0,           0],\n",
      "       [   0.096323,    0.096352,      0.1256, ...,           0,           0,           0],\n",
      "       [    0.07485,    0.074853,     0.12218, ...,     0.17267,           0,           0],\n",
      "       [    0.19802,     0.19802,     0.27368, ...,           0,           0,           0],\n",
      "       [   0.041667,    0.041699,    0.059387, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.016925,    0.016925,    0.025113, ...,           1,           1,           1],\n",
      "       [   0.050723,    0.050739,    0.067254, ...,           1,           1,           1],\n",
      "       [   0.039002,    0.039003,    0.065405, ...,           1,           1,           1],\n",
      "       [     0.1105,      0.1105,      0.1598, ...,           1,           1,           1],\n",
      "       [   0.021318,    0.021335,    0.030688, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,           0,           0,           0],\n",
      "       [    0.95385,     0.95385,     0.94872, ...,           0,           0,           0],\n",
      "       [    0.92593,     0.92593,     0.92593, ...,    0.094491,           0,           0],\n",
      "       [    0.95238,     0.95238,     0.95238, ...,           0,           0,           0],\n",
      "       [    0.91667,     0.91667,     0.91667, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
      "fitness: 0.49593101452700994\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.24765,     0.51454,     0.43772,     0.73172,     0.41522])\n",
      "names: {0: 'hole', 1: 'pole', 2: 'stairs', 3: 'bottle', 4: 'rock'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.6699214294583027, 'metrics/recall(B)': 0.7527269027269028, 'metrics/mAP50(B)': 0.7349890716120511, 'metrics/mAP50-95(B)': 0.46936900818422755, 'fitness': 0.49593101452700994}\n",
      "save_dir: PosixPath('runs/train/cvat_v4_smoother2')\n",
      "speed: {'preprocess': 0.5592489925396903, 'inference': 27.458799420403455, 'loss': 0.001257748784096587, 'postprocess': 0.7428461915367562}\n",
      "task: 'detect'\n",
      "Ultralytics 8.3.105 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2070 with Max-Q Design, 7959MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/labels/test.cache... 403 images, 281 backgrounds, 0 corrupt: 100%|██████████| 403/403 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:11<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        403        222      0.715      0.746      0.767      0.517\n",
      "                  hole          7         12      0.502      0.583      0.545      0.316\n",
      "                  pole         52        131      0.811      0.824      0.844       0.52\n",
      "                stairs         31         35      0.747      0.714      0.748      0.507\n",
      "                bottle         20         27      0.928      0.959      0.977       0.73\n",
      "                  rock         14         17      0.588      0.647       0.72      0.514\n",
      "Speed: 0.5ms preprocess, 25.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/cvat_v4_smoother3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:40:12,177 - INFO - Test set evaluation completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
      "\n",
      "ap_class_index: array([0, 1, 2, 3, 4])\n",
      "box: ultralytics.utils.metrics.Metric object\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7531bc6aa260>\n",
      "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
      "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.019324,    0.019324,           0],\n",
      "       [          1,           1,           1, ...,   0.0022531,   0.0011266,           0],\n",
      "       [          1,           1,           1, ...,   0.0029892,   0.0014946,           0],\n",
      "       [          1,           1,           1, ...,     0.50943,     0.50943,           0],\n",
      "       [          1,           1,           1, ...,     0.10968,     0.10968,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.032258,    0.032268,    0.043012, ...,           0,           0,           0],\n",
      "       [   0.097809,    0.097809,     0.12953, ...,           0,           0,           0],\n",
      "       [   0.081731,    0.081811,     0.11639, ...,    0.081271,           0,           0],\n",
      "       [    0.21429,     0.21429,     0.27616, ...,           0,           0,           0],\n",
      "       [   0.054226,    0.054226,      0.0774, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.016393,    0.016399,    0.022023, ...,           1,           1,           1],\n",
      "       [   0.051546,    0.051546,    0.069479, ...,           1,           1,           1],\n",
      "       [    0.04266,    0.042704,    0.061903, ...,           1,           1,           1],\n",
      "       [       0.12,        0.12,      0.1602, ...,           1,           1,           1],\n",
      "       [   0.027869,    0.027869,    0.040258, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
      "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
      "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
      "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
      "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
      "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
      "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
      "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
      "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
      "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
      "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
      "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
      "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
      "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
      "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
      "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
      "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
      "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
      "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
      "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
      "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
      "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
      "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
      "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
      "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
      "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
      "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
      "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
      "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
      "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
      "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
      "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
      "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
      "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
      "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
      "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
      "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
      "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
      "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
      "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
      "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
      "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,     0.91667, ...,           0,           0,           0],\n",
      "       [     0.9542,      0.9542,      0.9542, ...,           0,           0,           0],\n",
      "       [    0.97143,     0.97143,     0.97143, ...,    0.042357,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0],\n",
      "       [          1,           1,           1, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
      "fitness: 0.5423215582645715\n",
      "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
      "maps: array([    0.31593,     0.51966,     0.50708,     0.73049,     0.51364])\n",
      "names: {0: 'hole', 1: 'pole', 2: 'stairs', 3: 'bottle', 4: 'rock'}\n",
      "plot: True\n",
      "results_dict: {'metrics/precision(B)': 0.7151401976622289, 'metrics/recall(B)': 0.745578466948725, 'metrics/mAP50(B)': 0.766975154316298, 'metrics/mAP50-95(B)': 0.5173600475921575, 'fitness': 0.5423215582645715}\n",
      "save_dir: PosixPath('runs/train/cvat_v4_smoother3')\n",
      "speed: {'preprocess': 0.5399379900675922, 'inference': 25.438805553313156, 'loss': 0.0012286401976078457, 'postprocess': 0.7074671687204642}\n",
      "task: 'detect'\n",
      "Ultralytics 8.3.105 🚀 Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Core(TM) i7-9750H 2.60GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/train/cvat_v4_smoother/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 9, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.50...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.1s, saved as 'runs/train/cvat_v4_smoother/weights/best.onnx' (42.7 MB)\n",
      "\n",
      "Export complete (1.5s)\n",
      "Results saved to \u001b[1m/home/r0jin/projects/EnigmaAI/code/runs/train/cvat_v4_smoother/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs/train/cvat_v4_smoother/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs/train/cvat_v4_smoother/weights/best.onnx imgsz=640 data=/home/r0jin/projects/EnigmaAI/yolo_cvat_v4/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:40:13,661 - INFO - Model exported to ONNX format.\n"
     ]
    }
   ],
   "source": [
    "# --- Additional Validation ---\n",
    "val_results = model.val(data=str(data_yaml_path), split='val')\n",
    "logger.info(\"Validation completed on validation set.\")\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(val_results)\n",
    "\n",
    "# --- Test Set Evaluation ---\n",
    "test_results = model.val(data=str(data_yaml_path), split='test')\n",
    "logger.info(\"Test set evaluation completed.\")\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(test_results)\n",
    "\n",
    "# --- Export Model ---\n",
    "model.export(format='onnx')\n",
    "logger.info(\"Model exported to ONNX format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:40:16,189 - INFO - Saved annotation visualizations for labels in 'train_visualizations'.\n",
      "2025-04-11 12:40:18,466 - INFO - Saved annotation visualizations for labels in 'val_visualizations'.\n",
      "2025-04-11 12:40:20,725 - INFO - Saved annotation visualizations for labels in 'test_visualizations'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/images/test/frame_IMG_4925_00004.jpg: 640x640 (no detections), 33.6ms\n",
      "Speed: 1.2ms preprocess, 33.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/images/test/frame_IMG_4920_00008.jpg: 640x640 (no detections), 32.6ms\n",
      "Speed: 1.3ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/images/test/frame_IMG_4331_00023.jpg: 640x640 (no detections), 32.6ms\n",
      "Speed: 1.3ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/images/test/frame_IMG_4329_00021.jpg: 640x640 (no detections), 32.6ms\n",
      "Speed: 1.3ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/r0jin/projects/EnigmaAI/yolo_cvat_v4/images/test/frame_IMG_4941_00007.jpg: 640x640 2 poles, 32.5ms\n",
      "Speed: 1.3ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 12:40:23,053 - INFO - Saved test set prediction visualizations in 'test_predictions'.\n"
     ]
    }
   ],
   "source": [
    "# --- Visualize Test Set Predictions ---\n",
    "def visualize_predictions(model, image_dir, label_dir, class_names, num_samples=5, output_dir='test_predictions'):\n",
    "    \"\"\"Visualize model predictions on test set images with ground truth and predictions.\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_images = list(image_dir.glob('*.jpg'))\n",
    "    selected_images = random.sample(test_images, min(num_samples, len(test_images)))\n",
    "    \n",
    "    for img_path in selected_images:\n",
    "        # Load image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            logger.error(f\"Failed to load image: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Get ground truth annotations\n",
    "        lbl_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        gt_boxes = []\n",
    "        if lbl_path.exists():\n",
    "            with open(lbl_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        cls_id, x, y, w, h = map(float, line.split())\n",
    "                        gt_boxes.append((int(cls_id), x, y, w, h))\n",
    "        \n",
    "        # Run inference\n",
    "        results = model(img_path)\n",
    "        \n",
    "        # Plot ground truth and predictions\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Ground truth\n",
    "        ax[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax[0].set_title(\"Ground Truth\")\n",
    "        h, w = img.shape[:2]\n",
    "        for cls_id, x, y, width, height in gt_boxes:\n",
    "            x1 = int((x - width / 2) * w)\n",
    "            y1 = int((y - height / 2) * h)\n",
    "            x2 = int((x + width / 2) * w)\n",
    "            y2 = int((y + height / 2) * h)\n",
    "            ax[0].add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, edgecolor='green', facecolor='none', lw=2))\n",
    "            ax[0].text(x1, y1 - 10, class_names[int(cls_id)], color='green', fontsize=12)\n",
    "        \n",
    "        # Predictions\n",
    "        pred_img = results[0].plot()  # Plot predictions on the image\n",
    "        ax[1].imshow(pred_img)\n",
    "        ax[1].set_title(\"Predictions\")\n",
    "        \n",
    "        # Save figure\n",
    "        plt.savefig(output_path / f\"{img_path.stem}_pred.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    logger.info(f\"Saved test set prediction visualizations in '{output_dir}'.\")\n",
    "\n",
    "# --- Call Visualizations ---\n",
    "# Visualize sample annotations for all sets\n",
    "plot_samples_per_class(train_img_dir, train_lbl_dir, selected_classes, num_samples=3, output_dir='train_visualizations')\n",
    "plot_samples_per_class(val_img_dir, val_lbl_dir, selected_classes, num_samples=3, output_dir='val_visualizations')\n",
    "plot_samples_per_class(test_img_dir, test_lbl_dir, selected_classes, num_samples=3, output_dir='test_visualizations')\n",
    "\n",
    "# Visualize model predictions on test set\n",
    "visualize_predictions(model, test_img_dir, test_lbl_dir, selected_classes, num_samples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigmaAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
